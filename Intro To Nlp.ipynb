{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"London is the capital and most populous city of England and the United Kingdom. Standing on \n",
    "the River Thames in the south east of the island of Great Britain, \n",
    "London has been a major settlement for two millennia. It was founded by the Romans, who named it Londinium.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['London is the capital and most populous city of England and the United Kingdom.', 'Standing on \\nthe River Thames in the south east of the island of Great Britain, \\nLondon has been a major settlement for two millennia.', 'It was founded by the Romans, who named it Londinium.']\n"
     ]
    }
   ],
   "source": [
    "sent=list(sent_tokenize(text))\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(l):\n",
    "    i=0\n",
    "    words=[]\n",
    "    for j in l:\n",
    "        words.append(word_tokenize(j))\n",
    "        i=i+1\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['London', 'is', 'the', 'capital', 'and', 'most', 'populous', 'city', 'of', 'England', 'and', 'the', 'United', 'Kingdom', '.'], ['Standing', 'on', 'the', 'River', 'Thames', 'in', 'the', 'south', 'east', 'of', 'the', 'island', 'of', 'Great', 'Britain', ',', 'London', 'has', 'been', 'a', 'major', 'settlement', 'for', 'two', 'millennia', '.'], ['It', 'was', 'founded', 'by', 'the', 'Romans', ',', 'who', 'named', 'it', 'Londinium', '.']]\n"
     ]
    }
   ],
   "source": [
    "word=words(sent)\n",
    "print(word)\n",
    "token=word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words(l):\n",
    "    stop=[]\n",
    "    sr = stopwords.words('english')\n",
    "    for i in range(len(l)):\n",
    "        sent=[]\n",
    "        for j in range(len(l[i])):\n",
    "            if l[i][j] not in sr:\n",
    "                sent.append(l[i][j])\n",
    "        stop.append(sent)\n",
    "    return stop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['London', 'capital', 'populous', 'city', 'England', 'United', 'Kingdom', '.'], ['Standing', 'River', 'Thames', 'south', 'east', 'island', 'Great', 'Britain', ',', 'London', 'major', 'settlement', 'two', 'millennia', '.'], ['It', 'founded', 'Romans', ',', 'named', 'Londinium', '.']]\n"
     ]
    }
   ],
   "source": [
    "stop=stop_words(token)\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('London', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('capital', 'NN'), ('and', 'CC'), ('most', 'RBS'), ('populous', 'JJ'), ('city', 'NN'), ('of', 'IN'), ('England', 'NNP'), ('and', 'CC'), ('the', 'DT'), ('United', 'NNP'), ('Kingdom', 'NNP'), ('.', '.')], [('Standing', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('River', 'NNP'), ('Thames', 'NNP'), ('in', 'IN'), ('the', 'DT'), ('south', 'JJ'), ('east', 'NN'), ('of', 'IN'), ('the', 'DT'), ('island', 'NN'), ('of', 'IN'), ('Great', 'NNP'), ('Britain', 'NNP'), (',', ','), ('London', 'NNP'), ('has', 'VBZ'), ('been', 'VBN'), ('a', 'DT'), ('major', 'JJ'), ('settlement', 'NN'), ('for', 'IN'), ('two', 'CD'), ('millennia', 'NN'), ('.', '.')], [('It', 'PRP'), ('was', 'VBD'), ('founded', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('Romans', 'NNPS'), (',', ','), ('who', 'WP'), ('named', 'VBD'), ('it', 'PRP'), ('Londinium', 'NNP'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "def part_speech(word):\n",
    "    wr=word\n",
    "    for i in range(len(wr)):\n",
    "        wr[i]=pos_tag(wr[i])\n",
    "    return wr\n",
    "print(part_speech(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemminization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_stem(w):\n",
    "    return lancaster_stemmer.stem(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'words = [\"program\", \"programs\", \"programer\", \"programing\", \"programers\"] \\nps=PorterStemmer()\\nfor w in words: \\n    print(w, \" : \", ps.stem(w))'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"words = [\"program\", \"programs\", \"programer\", \"programing\", \"programers\"] \n",
    "ps=PorterStemmer()\n",
    "for w in words: \n",
    "    print(w, \" : \", ps.stem(w))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "def stem(l):\n",
    "    for i in range(len(l)):\n",
    "        for j in range(len(l[i])):\n",
    "            l[i][j]=stemmer.stem(l[i][j])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemr=stem(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['london', 'capit', 'pop', 'city', 'england', 'unit', 'kingdom', '.'], ['stand', 'riv', 'tham', 'sou', 'east', 'island', 'gre', 'britain', ',', 'london', 'maj', 'settl', 'two', 'millenn', '.'], ['it', 'found', 'rom', ',', 'nam', 'londin', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(stemr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('london', 'NN'), ('capit', 'JJ'), ('pop', 'NN'), ('city', 'NN'), ('england', 'VBP'), ('unit', 'NN'), ('kingdom', 'NN'), ('.', '.')], [('stand', 'NN'), ('riv', 'NN'), ('tham', 'NN'), ('sou', 'VBD'), ('east', 'JJ'), ('island', 'NN'), ('gre', 'NN'), ('britain', 'NN'), (',', ','), ('london', 'JJ'), ('maj', 'NN'), ('settl', 'VBD'), ('two', 'CD'), ('millenn', 'NN'), ('.', '.')], [('it', 'PRP'), ('found', 'VBD'), ('rom', 'NN'), (',', ','), ('nam', 'JJ'), ('londin', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "par=part_speech(stemr)\n",
    "print(stemr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = CoreNLPDependencyParser()\n",
    "#for i in stemr:\n",
    "#    parse = next(parser.raw_parse(i))\n",
    "#parse = next(parser.raw_parse(sent[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
