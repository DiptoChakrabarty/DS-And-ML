{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import  GridSearchCV,KFold\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "Pregnancies                 768 non-null int64\n",
      "Glucose                     768 non-null int64\n",
      "BloodPressure               768 non-null int64\n",
      "SkinThickness               768 non-null int64\n",
      "Insulin                     768 non-null int64\n",
      "BMI                         768 non-null float64\n",
      "DiabetesPedigreeFunction    768 non-null float64\n",
      "Age                         768 non-null int64\n",
      "Outcome                     768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimum of glucose,BMI,BP shows out to be 0 (missing data/outlier)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.140</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>27.7</td>\n",
       "      <td>0.299</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.389</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.346</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "75             1        0             48             20        0  24.7   \n",
       "182            1        0             74             20       23  27.7   \n",
       "342            1        0             68             35        0  32.0   \n",
       "349            5        0             80             32        0  41.0   \n",
       "502            6        0             68             41        0  39.0   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "75                      0.140   22        0  \n",
       "182                     0.299   21        0  \n",
       "342                     0.389   22        0  \n",
       "349                     0.346   37        1  \n",
       "502                     0.727   41        1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"Glucose\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>7</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>75</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>64</td>\n",
       "      <td>23</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.731</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>6</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  \\\n",
       "9              8      125             96              0        0  0.0   \n",
       "49             7      105              0              0        0  0.0   \n",
       "60             2       84              0              0        0  0.0   \n",
       "81             2       74              0              0        0  0.0   \n",
       "145            0      102             75             23        0  0.0   \n",
       "371            0      118             64             23       89  0.0   \n",
       "426            0       94              0              0        0  0.0   \n",
       "494            3       80              0              0        0  0.0   \n",
       "522            6      114              0              0        0  0.0   \n",
       "684            5      136             82              0        0  0.0   \n",
       "706           10      115              0              0        0  0.0   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "9                       0.232   54        1  \n",
       "49                      0.305   24        0  \n",
       "60                      0.304   21        0  \n",
       "81                      0.102   22        0  \n",
       "145                     0.572   21        0  \n",
       "371                     1.731   21        0  \n",
       "426                     0.256   25        0  \n",
       "494                     0.174   22        0  \n",
       "522                     0.189   26        0  \n",
       "684                     0.640   69        0  \n",
       "706                     0.261   30        1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"BMI\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Dataset:  (768, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Dataset: \",data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 0 for these columns by numpy Nan\n",
    "cols=[\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\"]\n",
    "\n",
    "for c in cols:\n",
    "    data[c].replace(0,np.NaN,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>763.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>541.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>121.686763</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.153420</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.457464</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>30.535641</td>\n",
       "      <td>12.382158</td>\n",
       "      <td>10.476982</td>\n",
       "      <td>118.775855</td>\n",
       "      <td>6.924988</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>32.300000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  763.000000     733.000000     541.000000  394.000000   \n",
       "mean      3.845052  121.686763      72.405184      29.153420  155.548223   \n",
       "std       3.369578   30.535641      12.382158      10.476982  118.775855   \n",
       "min       0.000000   44.000000      24.000000       7.000000   14.000000   \n",
       "25%       1.000000   99.000000      64.000000      22.000000   76.250000   \n",
       "50%       3.000000  117.000000      72.000000      29.000000  125.000000   \n",
       "75%       6.000000  141.000000      80.000000      36.000000  190.000000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  757.000000                768.000000  768.000000  768.000000  \n",
       "mean    32.457464                  0.471876   33.240885    0.348958  \n",
       "std      6.924988                  0.331329   11.760232    0.476951  \n",
       "min     18.200000                  0.078000   21.000000    0.000000  \n",
       "25%     27.500000                  0.243750   24.000000    0.000000  \n",
       "50%     32.300000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   0\n",
       "Glucose                       5\n",
       "BloodPressure                35\n",
       "SkinThickness               227\n",
       "Insulin                     374\n",
       "BMI                          11\n",
       "DiabetesPedigreeFunction      0\n",
       "Age                           0\n",
       "Outcome                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Dataset:  (392, 9)\n"
     ]
    }
   ],
   "source": [
    "# Remove Null Values\n",
    "data.dropna(inplace=True)\n",
    "print(\"Shape of Dataset: \",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.301020</td>\n",
       "      <td>122.627551</td>\n",
       "      <td>70.663265</td>\n",
       "      <td>29.145408</td>\n",
       "      <td>156.056122</td>\n",
       "      <td>33.086224</td>\n",
       "      <td>0.523046</td>\n",
       "      <td>30.864796</td>\n",
       "      <td>0.331633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.211424</td>\n",
       "      <td>30.860781</td>\n",
       "      <td>12.496092</td>\n",
       "      <td>10.516424</td>\n",
       "      <td>118.841690</td>\n",
       "      <td>7.027659</td>\n",
       "      <td>0.345488</td>\n",
       "      <td>10.200777</td>\n",
       "      <td>0.471401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>76.750000</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>0.269750</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>0.449500</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>37.100000</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   392.000000  392.000000     392.000000     392.000000  392.000000   \n",
       "mean      3.301020  122.627551      70.663265      29.145408  156.056122   \n",
       "std       3.211424   30.860781      12.496092      10.516424  118.841690   \n",
       "min       0.000000   56.000000      24.000000       7.000000   14.000000   \n",
       "25%       1.000000   99.000000      62.000000      21.000000   76.750000   \n",
       "50%       2.000000  119.000000      70.000000      29.000000  125.500000   \n",
       "75%       5.000000  143.000000      78.000000      37.000000  190.000000   \n",
       "max      17.000000  198.000000     110.000000      63.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  392.000000                392.000000  392.000000  392.000000  \n",
       "mean    33.086224                  0.523046   30.864796    0.331633  \n",
       "std      7.027659                  0.345488   10.200777    0.471401  \n",
       "min     18.200000                  0.085000   21.000000    0.000000  \n",
       "25%     28.400000                  0.269750   23.000000    0.000000  \n",
       "50%     33.200000                  0.449500   27.000000    0.000000  \n",
       "75%     37.100000                  0.687000   36.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop([\"Outcome\"],axis=1)\n",
    "y=data[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (392, 8)\n",
      "Shape of y: (392,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X:\",X.shape)\n",
    "print(\"Shape of y:\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "3             1     89.0           66.0           23.0     94.0  28.1   \n",
       "4             0    137.0           40.0           35.0    168.0  43.1   \n",
       "6             3     78.0           50.0           32.0     88.0  31.0   \n",
       "8             2    197.0           70.0           45.0    543.0  30.5   \n",
       "13            1    189.0           60.0           23.0    846.0  30.1   \n",
       "\n",
       "    DiabetesPedigreeFunction  Age  \n",
       "3                      0.167   21  \n",
       "4                      2.288   33  \n",
       "6                      0.248   26  \n",
       "8                      0.158   53  \n",
       "13                     0.398   59  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalise the Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.021726e-17</td>\n",
       "      <td>3.129583e-17</td>\n",
       "      <td>-4.641624e-16</td>\n",
       "      <td>1.042250e-16</td>\n",
       "      <td>6.485742e-17</td>\n",
       "      <td>1.543550e-16</td>\n",
       "      <td>3.880116e-17</td>\n",
       "      <td>1.028089e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.029213e+00</td>\n",
       "      <td>-2.161731e+00</td>\n",
       "      <td>-3.739001e+00</td>\n",
       "      <td>-2.108484e+00</td>\n",
       "      <td>-1.196867e+00</td>\n",
       "      <td>-2.120941e+00</td>\n",
       "      <td>-1.269525e+00</td>\n",
       "      <td>-9.682991e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.174265e-01</td>\n",
       "      <td>-7.665958e-01</td>\n",
       "      <td>-6.941640e-01</td>\n",
       "      <td>-7.755315e-01</td>\n",
       "      <td>-6.681786e-01</td>\n",
       "      <td>-6.676780e-01</td>\n",
       "      <td>-7.340909e-01</td>\n",
       "      <td>-7.719850e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.056403e-01</td>\n",
       "      <td>-1.176959e-01</td>\n",
       "      <td>-5.314565e-02</td>\n",
       "      <td>-1.384444e-02</td>\n",
       "      <td>-2.574448e-01</td>\n",
       "      <td>1.621036e-02</td>\n",
       "      <td>-2.131475e-01</td>\n",
       "      <td>-3.793569e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.297185e-01</td>\n",
       "      <td>6.609841e-01</td>\n",
       "      <td>5.878727e-01</td>\n",
       "      <td>7.478426e-01</td>\n",
       "      <td>2.859877e-01</td>\n",
       "      <td>5.718696e-01</td>\n",
       "      <td>4.751644e-01</td>\n",
       "      <td>5.040564e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.271153e+00</td>\n",
       "      <td>2.445459e+00</td>\n",
       "      <td>3.151946e+00</td>\n",
       "      <td>3.223325e+00</td>\n",
       "      <td>5.812990e+00</td>\n",
       "      <td>4.846172e+00</td>\n",
       "      <td>5.497667e+00</td>\n",
       "      <td>4.921123e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  3.920000e+02  3.920000e+02  3.920000e+02  3.920000e+02  3.920000e+02   \n",
       "mean  -4.021726e-17  3.129583e-17 -4.641624e-16  1.042250e-16  6.485742e-17   \n",
       "std    1.001278e+00  1.001278e+00  1.001278e+00  1.001278e+00  1.001278e+00   \n",
       "min   -1.029213e+00 -2.161731e+00 -3.739001e+00 -2.108484e+00 -1.196867e+00   \n",
       "25%   -7.174265e-01 -7.665958e-01 -6.941640e-01 -7.755315e-01 -6.681786e-01   \n",
       "50%   -4.056403e-01 -1.176959e-01 -5.314565e-02 -1.384444e-02 -2.574448e-01   \n",
       "75%    5.297185e-01  6.609841e-01  5.878727e-01  7.478426e-01  2.859877e-01   \n",
       "max    4.271153e+00  2.445459e+00  3.151946e+00  3.223325e+00  5.812990e+00   \n",
       "\n",
       "                  5             6             7  \n",
       "count  3.920000e+02  3.920000e+02  3.920000e+02  \n",
       "mean   1.543550e-16  3.880116e-17  1.028089e-16  \n",
       "std    1.001278e+00  1.001278e+00  1.001278e+00  \n",
       "min   -2.120941e+00 -1.269525e+00 -9.682991e-01  \n",
       "25%   -6.676780e-01 -7.340909e-01 -7.719850e-01  \n",
       "50%    1.621036e-02 -2.131475e-01 -3.793569e-01  \n",
       "75%    5.718696e-01  4.751644e-01  5.040564e-01  \n",
       "max    4.846172e+00  5.497667e+00  4.921123e+00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std=scaler.transform(X)\n",
    "\n",
    "Xfin=pd.DataFrame(X_std)\n",
    "\n",
    "Xfin.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.717427</td>\n",
       "      <td>-1.091046</td>\n",
       "      <td>-0.373655</td>\n",
       "      <td>-0.585110</td>\n",
       "      <td>-0.522842</td>\n",
       "      <td>-0.710421</td>\n",
       "      <td>-1.031876</td>\n",
       "      <td>-0.968299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.029213</td>\n",
       "      <td>0.466314</td>\n",
       "      <td>-2.456964</td>\n",
       "      <td>0.557421</td>\n",
       "      <td>0.100631</td>\n",
       "      <td>1.426730</td>\n",
       "      <td>5.115111</td>\n",
       "      <td>0.209585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.093854</td>\n",
       "      <td>-1.447941</td>\n",
       "      <td>-1.655691</td>\n",
       "      <td>0.271788</td>\n",
       "      <td>-0.573394</td>\n",
       "      <td>-0.297238</td>\n",
       "      <td>-0.797126</td>\n",
       "      <td>-0.477514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.405640</td>\n",
       "      <td>2.413014</td>\n",
       "      <td>-0.053146</td>\n",
       "      <td>1.509530</td>\n",
       "      <td>3.260122</td>\n",
       "      <td>-0.368477</td>\n",
       "      <td>-1.057960</td>\n",
       "      <td>2.172726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.717427</td>\n",
       "      <td>2.153454</td>\n",
       "      <td>-0.854419</td>\n",
       "      <td>-0.585110</td>\n",
       "      <td>5.812990</td>\n",
       "      <td>-0.425468</td>\n",
       "      <td>-0.362402</td>\n",
       "      <td>2.761668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.717427 -1.091046 -0.373655 -0.585110 -0.522842 -0.710421 -1.031876   \n",
       "1 -1.029213  0.466314 -2.456964  0.557421  0.100631  1.426730  5.115111   \n",
       "2 -0.093854 -1.447941 -1.655691  0.271788 -0.573394 -0.297238 -0.797126   \n",
       "3 -0.405640  2.413014 -0.053146  1.509530  3.260122 -0.368477 -1.057960   \n",
       "4 -0.717427  2.153454 -0.854419 -0.585110  5.812990 -0.425468 -0.362402   \n",
       "\n",
       "          7  \n",
       "0 -0.968299  \n",
       "1  0.209585  \n",
       "2 -0.477514  \n",
       "3  2.172726  \n",
       "4  2.761668  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xfin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=8, step=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xfin.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to define Model\n",
    "def  model_create():\n",
    "    #Create Model\n",
    "    model=Sequential()\n",
    "    model.add(Dense(8,input_dim=8,kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dense(4,input_dim=8,kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    #Compile The Model\n",
    "    adam = Adam(lr =0.01)\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dipto\\Anaconda33\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 113\n",
      "Trainable params: 113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=model_create()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dipto\\Anaconda33\\lib\\site-packages\\sklearn\\model_selection\\_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dipto\\Anaconda33\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "261/261 [==============================] - 5s 20ms/step - loss: 0.6263 - acc: 0.6935\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 278us/step - loss: 0.4782 - acc: 0.6973\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 354us/step - loss: 0.4373 - acc: 0.6973\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 332us/step - loss: 0.4240 - acc: 0.7011\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 266us/step - loss: 0.4130 - acc: 0.8008\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 227us/step - loss: 0.4001 - acc: 0.8352\n",
      "Epoch 7/10\n",
      "261/261 [==============================] - 0s 205us/step - loss: 0.3900 - acc: 0.8391\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 183us/step - loss: 0.3877 - acc: 0.8238\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - 0s 183us/step - loss: 0.3906 - acc: 0.8391\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 198us/step - loss: 0.3753 - acc: 0.8391\n",
      "131/131 [==============================] - 0s 2ms/step\n",
      "[CV] ............ batch_size=10, epochs=10, score=0.740, total=   7.9s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "261/261 [==============================] - 1s 5ms/step - loss: 0.6398 - acc: 0.6475\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 189us/step - loss: 0.5226 - acc: 0.6552\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 236us/step - loss: 0.4920 - acc: 0.6552\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 194us/step - loss: 0.4815 - acc: 0.7011\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 199us/step - loss: 0.4743 - acc: 0.7893\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 192us/step - loss: 0.4616 - acc: 0.8084\n",
      "Epoch 7/10\n",
      "261/261 [==============================] - ETA: 0s - loss: 0.4551 - acc: 0.800 - 0s 207us/step - loss: 0.4546 - acc: 0.8008\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 221us/step - loss: 0.4464 - acc: 0.8046\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - 0s 200us/step - loss: 0.4344 - acc: 0.8046\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 247us/step - loss: 0.4307 - acc: 0.8123\n",
      "131/131 [==============================] - 0s 2ms/step\n",
      "[CV] ............ batch_size=10, epochs=10, score=0.756, total=   3.3s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   11.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.6440 - acc: 0.6374\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 0s 222us/step - loss: 0.5278 - acc: 0.6527\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 0s 207us/step - loss: 0.5030 - acc: 0.7328\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 0s 200us/step - loss: 0.4998 - acc: 0.7557\n",
      "Epoch 5/10\n",
      "262/262 [==============================] - 0s 190us/step - loss: 0.4917 - acc: 0.7519\n",
      "Epoch 6/10\n",
      "262/262 [==============================] - 0s 205us/step - loss: 0.4881 - acc: 0.7595\n",
      "Epoch 7/10\n",
      "262/262 [==============================] - 0s 182us/step - loss: 0.4830 - acc: 0.7595\n",
      "Epoch 8/10\n",
      "262/262 [==============================] - 0s 138us/step - loss: 0.4786 - acc: 0.7710\n",
      "Epoch 9/10\n",
      "262/262 [==============================] - 0s 190us/step - loss: 0.4716 - acc: 0.7786\n",
      "Epoch 10/10\n",
      "262/262 [==============================] - 0s 174us/step - loss: 0.4803 - acc: 0.7786\n",
      "130/130 [==============================] - 0s 2ms/step\n",
      "[CV] ............ batch_size=10, epochs=10, score=0.831, total=   3.3s\n",
      "[CV] batch_size=10, epochs=25 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   14.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "261/261 [==============================] - 1s 5ms/step - loss: 0.5916 - acc: 0.6820\n",
      "Epoch 2/25\n",
      "261/261 [==============================] - 0s 241us/step - loss: 0.4484 - acc: 0.6973\n",
      "Epoch 3/25\n",
      "261/261 [==============================] - 0s 153us/step - loss: 0.4235 - acc: 0.7280\n",
      "Epoch 4/25\n",
      "261/261 [==============================] - 0s 230us/step - loss: 0.4095 - acc: 0.8046\n",
      "Epoch 5/25\n",
      "261/261 [==============================] - 0s 237us/step - loss: 0.4029 - acc: 0.8199\n",
      "Epoch 6/25\n",
      "261/261 [==============================] - 0s 181us/step - loss: 0.3875 - acc: 0.8276\n",
      "Epoch 7/25\n",
      "261/261 [==============================] - 0s 221us/step - loss: 0.3758 - acc: 0.8199\n",
      "Epoch 8/25\n",
      "261/261 [==============================] - 0s 180us/step - loss: 0.3698 - acc: 0.8391\n",
      "Epoch 9/25\n",
      "261/261 [==============================] - 0s 212us/step - loss: 0.3751 - acc: 0.8161\n",
      "Epoch 10/25\n",
      "261/261 [==============================] - 0s 241us/step - loss: 0.3569 - acc: 0.8506\n",
      "Epoch 11/25\n",
      "261/261 [==============================] - 0s 208us/step - loss: 0.3584 - acc: 0.8314\n",
      "Epoch 12/25\n",
      "261/261 [==============================] - 0s 191us/step - loss: 0.3500 - acc: 0.8352\n",
      "Epoch 13/25\n",
      "261/261 [==============================] - 0s 184us/step - loss: 0.3464 - acc: 0.8314\n",
      "Epoch 14/25\n",
      "261/261 [==============================] - 0s 197us/step - loss: 0.3328 - acc: 0.8391\n",
      "Epoch 15/25\n",
      "261/261 [==============================] - 0s 220us/step - loss: 0.3282 - acc: 0.8467\n",
      "Epoch 16/25\n",
      "261/261 [==============================] - 0s 249us/step - loss: 0.3271 - acc: 0.8467\n",
      "Epoch 17/25\n",
      "261/261 [==============================] - 0s 248us/step - loss: 0.3376 - acc: 0.8352\n",
      "Epoch 18/25\n",
      "261/261 [==============================] - 0s 210us/step - loss: 0.3238 - acc: 0.8506\n",
      "Epoch 19/25\n",
      "261/261 [==============================] - 0s 223us/step - loss: 0.3139 - acc: 0.8582\n",
      "Epoch 20/25\n",
      "261/261 [==============================] - 0s 198us/step - loss: 0.3079 - acc: 0.8506\n",
      "Epoch 21/25\n",
      "261/261 [==============================] - 0s 226us/step - loss: 0.3066 - acc: 0.8659\n",
      "Epoch 22/25\n",
      "261/261 [==============================] - 0s 233us/step - loss: 0.3092 - acc: 0.8429\n",
      "Epoch 23/25\n",
      "261/261 [==============================] - 0s 214us/step - loss: 0.3025 - acc: 0.8621\n",
      "Epoch 24/25\n",
      "261/261 [==============================] - 0s 231us/step - loss: 0.3017 - acc: 0.8659\n",
      "Epoch 25/25\n",
      "261/261 [==============================] - 0s 226us/step - loss: 0.2891 - acc: 0.8736\n",
      "131/131 [==============================] - 0s 2ms/step\n",
      "[CV] ............ batch_size=10, epochs=25, score=0.718, total=   4.1s\n",
      "[CV] batch_size=10, epochs=25 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   18.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "261/261 [==============================] - 1s 6ms/step - loss: 0.5867 - acc: 0.6858\n",
      "Epoch 2/25\n",
      "261/261 [==============================] - 0s 244us/step - loss: 0.4836 - acc: 0.7586\n",
      "Epoch 3/25\n",
      "261/261 [==============================] - 0s 234us/step - loss: 0.4556 - acc: 0.7778\n",
      "Epoch 4/25\n",
      "261/261 [==============================] - 0s 196us/step - loss: 0.4474 - acc: 0.7854\n",
      "Epoch 5/25\n",
      "261/261 [==============================] - 0s 222us/step - loss: 0.4346 - acc: 0.7931\n",
      "Epoch 6/25\n",
      "261/261 [==============================] - 0s 201us/step - loss: 0.4254 - acc: 0.8046\n",
      "Epoch 7/25\n",
      "261/261 [==============================] - 0s 252us/step - loss: 0.4243 - acc: 0.8161\n",
      "Epoch 8/25\n",
      "261/261 [==============================] - 0s 319us/step - loss: 0.4126 - acc: 0.8199 0s - loss: 0.4060 - acc: 0.825\n",
      "Epoch 9/25\n",
      "261/261 [==============================] - 0s 276us/step - loss: 0.4177 - acc: 0.8199\n",
      "Epoch 10/25\n",
      "261/261 [==============================] - 0s 244us/step - loss: 0.4119 - acc: 0.8391\n",
      "Epoch 11/25\n",
      "261/261 [==============================] - 0s 233us/step - loss: 0.3953 - acc: 0.8238\n",
      "Epoch 12/25\n",
      "261/261 [==============================] - 0s 240us/step - loss: 0.3921 - acc: 0.8276\n",
      "Epoch 13/25\n",
      "261/261 [==============================] - 0s 304us/step - loss: 0.3857 - acc: 0.8314\n",
      "Epoch 14/25\n",
      "261/261 [==============================] - ETA: 0s - loss: 0.3845 - acc: 0.843 - 0s 319us/step - loss: 0.4010 - acc: 0.8199\n",
      "Epoch 15/25\n",
      "261/261 [==============================] - 0s 272us/step - loss: 0.3842 - acc: 0.8314\n",
      "Epoch 16/25\n",
      "261/261 [==============================] - 0s 242us/step - loss: 0.3901 - acc: 0.8276\n",
      "Epoch 17/25\n",
      "261/261 [==============================] - 0s 276us/step - loss: 0.3765 - acc: 0.8391\n",
      "Epoch 18/25\n",
      "261/261 [==============================] - 0s 318us/step - loss: 0.3792 - acc: 0.8429\n",
      "Epoch 19/25\n",
      "261/261 [==============================] - 0s 292us/step - loss: 0.3744 - acc: 0.8314\n",
      "Epoch 20/25\n",
      "261/261 [==============================] - 0s 224us/step - loss: 0.3668 - acc: 0.8352\n",
      "Epoch 21/25\n",
      "261/261 [==============================] - 0s 214us/step - loss: 0.3639 - acc: 0.8429\n",
      "Epoch 22/25\n",
      "261/261 [==============================] - 0s 234us/step - loss: 0.3552 - acc: 0.8391\n",
      "Epoch 23/25\n",
      "261/261 [==============================] - 0s 332us/step - loss: 0.3531 - acc: 0.8391\n",
      "Epoch 24/25\n",
      "261/261 [==============================] - 0s 267us/step - loss: 0.3574 - acc: 0.8429\n",
      "Epoch 25/25\n",
      "261/261 [==============================] - 0s 230us/step - loss: 0.3689 - acc: 0.8506\n",
      "131/131 [==============================] - 0s 3ms/step\n",
      "[CV] ............ batch_size=10, epochs=25, score=0.771, total=   4.6s\n",
      "[CV] batch_size=10, epochs=25 ........................................\n",
      "Epoch 1/25\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 0.6631 - acc: 0.6603\n",
      "Epoch 2/25\n",
      "262/262 [==============================] - 0s 255us/step - loss: 0.5549 - acc: 0.7519\n",
      "Epoch 3/25\n",
      "262/262 [==============================] - 0s 285us/step - loss: 0.4900 - acc: 0.7595\n",
      "Epoch 4/25\n",
      "262/262 [==============================] - 0s 338us/step - loss: 0.4765 - acc: 0.7557\n",
      "Epoch 5/25\n",
      "262/262 [==============================] - 0s 264us/step - loss: 0.4708 - acc: 0.7481\n",
      "Epoch 6/25\n",
      "262/262 [==============================] - 0s 241us/step - loss: 0.4592 - acc: 0.7672\n",
      "Epoch 7/25\n",
      "262/262 [==============================] - 0s 200us/step - loss: 0.4555 - acc: 0.7481\n",
      "Epoch 8/25\n",
      "262/262 [==============================] - 0s 263us/step - loss: 0.4532 - acc: 0.7634\n",
      "Epoch 9/25\n",
      "262/262 [==============================] - 0s 270us/step - loss: 0.4432 - acc: 0.7672\n",
      "Epoch 10/25\n",
      "262/262 [==============================] - 0s 283us/step - loss: 0.4407 - acc: 0.7863\n",
      "Epoch 11/25\n",
      "262/262 [==============================] - 0s 264us/step - loss: 0.4351 - acc: 0.7901\n",
      "Epoch 12/25\n",
      "262/262 [==============================] - 0s 249us/step - loss: 0.4374 - acc: 0.7786\n",
      "Epoch 13/25\n",
      "262/262 [==============================] - 0s 204us/step - loss: 0.4320 - acc: 0.8015\n",
      "Epoch 14/25\n",
      "262/262 [==============================] - 0s 213us/step - loss: 0.4416 - acc: 0.7824\n",
      "Epoch 15/25\n",
      "262/262 [==============================] - 0s 240us/step - loss: 0.4268 - acc: 0.7977\n",
      "Epoch 16/25\n",
      "262/262 [==============================] - 0s 315us/step - loss: 0.4364 - acc: 0.7863\n",
      "Epoch 17/25\n",
      "262/262 [==============================] - 0s 237us/step - loss: 0.4241 - acc: 0.8130\n",
      "Epoch 18/25\n",
      "262/262 [==============================] - 0s 190us/step - loss: 0.4242 - acc: 0.7901\n",
      "Epoch 19/25\n",
      "262/262 [==============================] - 0s 306us/step - loss: 0.4218 - acc: 0.7901\n",
      "Epoch 20/25\n",
      "262/262 [==============================] - 0s 238us/step - loss: 0.4277 - acc: 0.7939\n",
      "Epoch 21/25\n",
      "262/262 [==============================] - 0s 286us/step - loss: 0.4267 - acc: 0.7901\n",
      "Epoch 22/25\n",
      "262/262 [==============================] - 0s 269us/step - loss: 0.4140 - acc: 0.8168\n",
      "Epoch 23/25\n",
      "262/262 [==============================] - 0s 278us/step - loss: 0.4147 - acc: 0.7939\n",
      "Epoch 24/25\n",
      "262/262 [==============================] - 0s 244us/step - loss: 0.4081 - acc: 0.8053\n",
      "Epoch 25/25\n",
      "262/262 [==============================] - 0s 248us/step - loss: 0.4085 - acc: 0.8092\n",
      "130/130 [==============================] - 0s 2ms/step\n",
      "[CV] ............ batch_size=10, epochs=25, score=0.846, total=   4.8s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "261/261 [==============================] - 2s 6ms/step - loss: 0.6197 - acc: 0.6973\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 300us/step - loss: 0.4830 - acc: 0.6973\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 157us/step - loss: 0.4368 - acc: 0.6973\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 171us/step - loss: 0.4175 - acc: 0.7471\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 219us/step - loss: 0.4005 - acc: 0.8352\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 229us/step - loss: 0.3934 - acc: 0.8352\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 169us/step - loss: 0.3851 - acc: 0.8467\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 0s 247us/step - loss: 0.3722 - acc: 0.8467\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 222us/step - loss: 0.3656 - acc: 0.8506\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 191us/step - loss: 0.3591 - acc: 0.8544\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 175us/step - loss: 0.3511 - acc: 0.8352\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 247us/step - loss: 0.3512 - acc: 0.8506\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 191us/step - loss: 0.3457 - acc: 0.8582\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 230us/step - loss: 0.3540 - acc: 0.8391\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 180us/step - loss: 0.3335 - acc: 0.8544\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 202us/step - loss: 0.3325 - acc: 0.8582\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 0s 217us/step - loss: 0.3296 - acc: 0.8544\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 0s 181us/step - loss: 0.3258 - acc: 0.8659\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 299us/step - loss: 0.3178 - acc: 0.8697\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 258us/step - loss: 0.3190 - acc: 0.8621\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 245us/step - loss: 0.3096 - acc: 0.8812\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 231us/step - loss: 0.3097 - acc: 0.8812\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 262us/step - loss: 0.3064 - acc: 0.8659\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 178us/step - loss: 0.3182 - acc: 0.8621\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 229us/step - loss: 0.3014 - acc: 0.8736\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 240us/step - loss: 0.3158 - acc: 0.8697\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 172us/step - loss: 0.3109 - acc: 0.8621\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 236us/step - loss: 0.3158 - acc: 0.8659\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 245us/step - loss: 0.3063 - acc: 0.8851\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 191us/step - loss: 0.2970 - acc: 0.8812\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 223us/step - loss: 0.3088 - acc: 0.8774\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 186us/step - loss: 0.2967 - acc: 0.8812\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 262us/step - loss: 0.2934 - acc: 0.8736\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 172us/step - loss: 0.2962 - acc: 0.8889\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 216us/step - loss: 0.2912 - acc: 0.8774\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 258us/step - loss: 0.2906 - acc: 0.8927\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 271us/step - loss: 0.2976 - acc: 0.8927\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 218us/step - loss: 0.2839 - acc: 0.8927\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 0s 217us/step - loss: 0.2922 - acc: 0.8927\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 229us/step - loss: 0.2874 - acc: 0.8812\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 226us/step - loss: 0.2857 - acc: 0.9119\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 246us/step - loss: 0.2848 - acc: 0.8927\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 0s 241us/step - loss: 0.2886 - acc: 0.8966\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 182us/step - loss: 0.2837 - acc: 0.8889\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 229us/step - loss: 0.2926 - acc: 0.8812\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - ETA: 0s - loss: 0.0616 - acc: 1.000 - 0s 210us/step - loss: 0.2837 - acc: 0.8812\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 0s 157us/step - loss: 0.2977 - acc: 0.8851\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - ETA: 0s - loss: 0.2486 - acc: 0.900 - 0s 162us/step - loss: 0.3087 - acc: 0.8582\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 167us/step - loss: 0.2836 - acc: 0.8851\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 225us/step - loss: 0.2834 - acc: 0.9004\n",
      "131/131 [==============================] - 0s 3ms/step\n",
      "[CV] ............ batch_size=10, epochs=50, score=0.756, total=   5.8s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "261/261 [==============================] - 2s 6ms/step - loss: 0.6438 - acc: 0.6973\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 238us/step - loss: 0.4886 - acc: 0.7816\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 187us/step - loss: 0.4566 - acc: 0.7739\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 249us/step - loss: 0.4397 - acc: 0.7854\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 251us/step - loss: 0.4270 - acc: 0.8084\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 225us/step - loss: 0.4198 - acc: 0.8008\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 225us/step - loss: 0.4096 - acc: 0.8161\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 0s 198us/step - loss: 0.3983 - acc: 0.8238\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 253us/step - loss: 0.4008 - acc: 0.8276\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 266us/step - loss: 0.3950 - acc: 0.8276\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 230us/step - loss: 0.3904 - acc: 0.8391\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 240us/step - loss: 0.3889 - acc: 0.8391\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 242us/step - loss: 0.3839 - acc: 0.8391\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 197us/step - loss: 0.3802 - acc: 0.8238\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 261us/step - loss: 0.3767 - acc: 0.8352\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 189us/step - loss: 0.3763 - acc: 0.8467\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 0s 214us/step - loss: 0.3761 - acc: 0.8391\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 0s 194us/step - loss: 0.3746 - acc: 0.8314\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 276us/step - loss: 0.3723 - acc: 0.8429\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 235us/step - loss: 0.3717 - acc: 0.8544\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 164us/step - loss: 0.3716 - acc: 0.8429\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 239us/step - loss: 0.3677 - acc: 0.8429\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 239us/step - loss: 0.3678 - acc: 0.8352\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 226us/step - loss: 0.3697 - acc: 0.8429\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 225us/step - loss: 0.3757 - acc: 0.8161\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 217us/step - loss: 0.3699 - acc: 0.8544\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 235us/step - loss: 0.3770 - acc: 0.8467\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 247us/step - loss: 0.3667 - acc: 0.8314\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 260us/step - loss: 0.3653 - acc: 0.8352\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 0s 232us/step - loss: 0.3599 - acc: 0.8429\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 152us/step - loss: 0.3596 - acc: 0.8467\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 213us/step - loss: 0.3564 - acc: 0.8429\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 252us/step - loss: 0.3586 - acc: 0.8352\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 224us/step - loss: 0.3507 - acc: 0.8544\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 243us/step - loss: 0.3564 - acc: 0.8467\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 194us/step - loss: 0.3504 - acc: 0.8467\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 260us/step - loss: 0.3484 - acc: 0.8429\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 218us/step - loss: 0.3584 - acc: 0.8352\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 0s 244us/step - loss: 0.3521 - acc: 0.8506\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 245us/step - loss: 0.3459 - acc: 0.8506\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 230us/step - loss: 0.3421 - acc: 0.8544\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 210us/step - loss: 0.3385 - acc: 0.8582\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 0s 281us/step - loss: 0.3427 - acc: 0.8467\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 285us/step - loss: 0.3398 - acc: 0.8467\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 304us/step - loss: 0.3454 - acc: 0.8506\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 0s 231us/step - loss: 0.3383 - acc: 0.8506\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 0s 244us/step - loss: 0.3330 - acc: 0.8506\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 0s 247us/step - loss: 0.3307 - acc: 0.8621\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 218us/step - loss: 0.3329 - acc: 0.8621\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 219us/step - loss: 0.3465 - acc: 0.8391\n",
      "131/131 [==============================] - 0s 3ms/step\n",
      "[CV] ............ batch_size=10, epochs=50, score=0.763, total=   6.0s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "262/262 [==============================] - 2s 6ms/step - loss: 0.6282 - acc: 0.6489\n",
      "Epoch 2/50\n",
      "262/262 [==============================] - 0s 247us/step - loss: 0.5149 - acc: 0.6527\n",
      "Epoch 3/50\n",
      "262/262 [==============================] - 0s 241us/step - loss: 0.5029 - acc: 0.6679\n",
      "Epoch 4/50\n",
      "262/262 [==============================] - 0s 188us/step - loss: 0.4938 - acc: 0.7366\n",
      "Epoch 5/50\n",
      "262/262 [==============================] - 0s 263us/step - loss: 0.4886 - acc: 0.7595\n",
      "Epoch 6/50\n",
      "262/262 [==============================] - 0s 224us/step - loss: 0.4785 - acc: 0.7748\n",
      "Epoch 7/50\n",
      "262/262 [==============================] - 0s 176us/step - loss: 0.4780 - acc: 0.7710\n",
      "Epoch 8/50\n",
      "262/262 [==============================] - 0s 220us/step - loss: 0.4681 - acc: 0.7748\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 0s 175us/step - loss: 0.4574 - acc: 0.7901\n",
      "Epoch 10/50\n",
      "262/262 [==============================] - 0s 182us/step - loss: 0.4493 - acc: 0.8015\n",
      "Epoch 11/50\n",
      "262/262 [==============================] - 0s 222us/step - loss: 0.4450 - acc: 0.7977\n",
      "Epoch 12/50\n",
      "262/262 [==============================] - 0s 242us/step - loss: 0.4397 - acc: 0.7939\n",
      "Epoch 13/50\n",
      "262/262 [==============================] - 0s 226us/step - loss: 0.4364 - acc: 0.8015\n",
      "Epoch 14/50\n",
      "262/262 [==============================] - 0s 264us/step - loss: 0.4265 - acc: 0.8053\n",
      "Epoch 15/50\n",
      "262/262 [==============================] - 0s 223us/step - loss: 0.4269 - acc: 0.8092\n",
      "Epoch 16/50\n",
      "262/262 [==============================] - 0s 226us/step - loss: 0.4229 - acc: 0.8130\n",
      "Epoch 17/50\n",
      "262/262 [==============================] - 0s 316us/step - loss: 0.4195 - acc: 0.8206\n",
      "Epoch 18/50\n",
      "262/262 [==============================] - 0s 194us/step - loss: 0.4183 - acc: 0.8282\n",
      "Epoch 19/50\n",
      "262/262 [==============================] - 0s 181us/step - loss: 0.4151 - acc: 0.8359\n",
      "Epoch 20/50\n",
      "262/262 [==============================] - 0s 177us/step - loss: 0.4116 - acc: 0.8321\n",
      "Epoch 21/50\n",
      "262/262 [==============================] - 0s 232us/step - loss: 0.4080 - acc: 0.8206\n",
      "Epoch 22/50\n",
      "262/262 [==============================] - 0s 220us/step - loss: 0.4058 - acc: 0.8206\n",
      "Epoch 23/50\n",
      "262/262 [==============================] - 0s 234us/step - loss: 0.4004 - acc: 0.8359\n",
      "Epoch 24/50\n",
      "262/262 [==============================] - 0s 245us/step - loss: 0.4021 - acc: 0.8244\n",
      "Epoch 25/50\n",
      "262/262 [==============================] - 0s 179us/step - loss: 0.4014 - acc: 0.8130\n",
      "Epoch 26/50\n",
      "262/262 [==============================] - 0s 263us/step - loss: 0.4035 - acc: 0.8282\n",
      "Epoch 27/50\n",
      "262/262 [==============================] - 0s 245us/step - loss: 0.3999 - acc: 0.8130\n",
      "Epoch 28/50\n",
      "262/262 [==============================] - 0s 178us/step - loss: 0.3943 - acc: 0.8168\n",
      "Epoch 29/50\n",
      "262/262 [==============================] - 0s 218us/step - loss: 0.3973 - acc: 0.8168\n",
      "Epoch 30/50\n",
      "262/262 [==============================] - 0s 230us/step - loss: 0.3906 - acc: 0.8321\n",
      "Epoch 31/50\n",
      "262/262 [==============================] - 0s 239us/step - loss: 0.3909 - acc: 0.8282\n",
      "Epoch 32/50\n",
      "262/262 [==============================] - 0s 239us/step - loss: 0.3881 - acc: 0.8359\n",
      "Epoch 33/50\n",
      "262/262 [==============================] - 0s 249us/step - loss: 0.3882 - acc: 0.8282\n",
      "Epoch 34/50\n",
      "262/262 [==============================] - 0s 280us/step - loss: 0.3857 - acc: 0.8168\n",
      "Epoch 35/50\n",
      "262/262 [==============================] - 0s 215us/step - loss: 0.3906 - acc: 0.8282\n",
      "Epoch 36/50\n",
      "262/262 [==============================] - 0s 228us/step - loss: 0.4028 - acc: 0.8206\n",
      "Epoch 37/50\n",
      "262/262 [==============================] - 0s 189us/step - loss: 0.3847 - acc: 0.8397\n",
      "Epoch 38/50\n",
      "262/262 [==============================] - 0s 242us/step - loss: 0.3821 - acc: 0.8397\n",
      "Epoch 39/50\n",
      "262/262 [==============================] - 0s 168us/step - loss: 0.3761 - acc: 0.8244\n",
      "Epoch 40/50\n",
      "262/262 [==============================] - 0s 220us/step - loss: 0.3783 - acc: 0.8359\n",
      "Epoch 41/50\n",
      "262/262 [==============================] - 0s 220us/step - loss: 0.3951 - acc: 0.8359\n",
      "Epoch 42/50\n",
      "262/262 [==============================] - 0s 163us/step - loss: 0.3792 - acc: 0.8435\n",
      "Epoch 43/50\n",
      "262/262 [==============================] - 0s 168us/step - loss: 0.3919 - acc: 0.8244\n",
      "Epoch 44/50\n",
      "262/262 [==============================] - 0s 167us/step - loss: 0.3725 - acc: 0.8282\n",
      "Epoch 45/50\n",
      "262/262 [==============================] - 0s 213us/step - loss: 0.3726 - acc: 0.8397\n",
      "Epoch 46/50\n",
      "262/262 [==============================] - 0s 228us/step - loss: 0.3736 - acc: 0.8473\n",
      "Epoch 47/50\n",
      "262/262 [==============================] - 0s 162us/step - loss: 0.3712 - acc: 0.8359\n",
      "Epoch 48/50\n",
      "262/262 [==============================] - 0s 181us/step - loss: 0.3692 - acc: 0.8359\n",
      "Epoch 49/50\n",
      "262/262 [==============================] - 0s 291us/step - loss: 0.3656 - acc: 0.8473\n",
      "Epoch 50/50\n",
      "262/262 [==============================] - 0s 238us/step - loss: 0.3613 - acc: 0.8359\n",
      "130/130 [==============================] - 0s 3ms/step\n",
      "[CV] ............ batch_size=10, epochs=50, score=0.831, total=   5.9s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "261/261 [==============================] - 2s 6ms/step - loss: 0.6821 - acc: 0.6590\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 109us/step - loss: 0.6573 - acc: 0.7356\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 188us/step - loss: 0.6272 - acc: 0.8123\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 107us/step - loss: 0.5901 - acc: 0.8046\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 119us/step - loss: 0.5626 - acc: 0.8199\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 173us/step - loss: 0.5352 - acc: 0.8314\n",
      "Epoch 7/10\n",
      "261/261 [==============================] - 0s 97us/step - loss: 0.5120 - acc: 0.8314\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.4910 - acc: 0.8276\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - 0s 95us/step - loss: 0.4757 - acc: 0.8391\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.4619 - acc: 0.8276\n",
      "131/131 [==============================] - 0s 3ms/step\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.756, total=   3.4s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "261/261 [==============================] - 2s 7ms/step - loss: 0.6834 - acc: 0.6437\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 118us/step - loss: 0.6568 - acc: 0.7050\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 138us/step - loss: 0.6205 - acc: 0.7778\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 126us/step - loss: 0.5900 - acc: 0.7931\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.5634 - acc: 0.7854\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.5443 - acc: 0.7931\n",
      "Epoch 7/10\n",
      "261/261 [==============================] - 0s 130us/step - loss: 0.5302 - acc: 0.7778\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 112us/step - loss: 0.5228 - acc: 0.7893\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - 0s 150us/step - loss: 0.5064 - acc: 0.7969\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 134us/step - loss: 0.4968 - acc: 0.7893\n",
      "131/131 [==============================] - 0s 3ms/step\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.763, total=   3.4s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "262/262 [==============================] - 2s 7ms/step - loss: 0.6502 - acc: 0.6412\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 0s 112us/step - loss: 0.5269 - acc: 0.6527\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 0s 124us/step - loss: 0.5070 - acc: 0.6527\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 0s 137us/step - loss: 0.4988 - acc: 0.6870\n",
      "Epoch 5/10\n",
      "262/262 [==============================] - 0s 122us/step - loss: 0.4884 - acc: 0.7710\n",
      "Epoch 6/10\n",
      "262/262 [==============================] - 0s 146us/step - loss: 0.4907 - acc: 0.7710\n",
      "Epoch 7/10\n",
      "262/262 [==============================] - 0s 132us/step - loss: 0.4807 - acc: 0.7519\n",
      "Epoch 8/10\n",
      "262/262 [==============================] - 0s 135us/step - loss: 0.4781 - acc: 0.7672\n",
      "Epoch 9/10\n",
      "262/262 [==============================] - 0s 110us/step - loss: 0.4722 - acc: 0.7863\n",
      "Epoch 10/10\n",
      "262/262 [==============================] - 0s 145us/step - loss: 0.4680 - acc: 0.7824\n",
      "130/130 [==============================] - 0s 4ms/step\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.815, total=   3.5s\n",
      "[CV] batch_size=20, epochs=25 ........................................\n",
      "Epoch 1/25\n",
      "261/261 [==============================] - 2s 7ms/step - loss: 0.6524 - acc: 0.6973\n",
      "Epoch 2/25\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.5137 - acc: 0.6973\n",
      "Epoch 3/25\n",
      "261/261 [==============================] - 0s 137us/step - loss: 0.4497 - acc: 0.7739\n",
      "Epoch 4/25\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.4153 - acc: 0.8008\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 132us/step - loss: 0.3952 - acc: 0.8046\n",
      "Epoch 6/25\n",
      "261/261 [==============================] - 0s 145us/step - loss: 0.3885 - acc: 0.8276\n",
      "Epoch 7/25\n",
      "261/261 [==============================] - 0s 137us/step - loss: 0.3862 - acc: 0.8199\n",
      "Epoch 8/25\n",
      "261/261 [==============================] - 0s 125us/step - loss: 0.3773 - acc: 0.8199\n",
      "Epoch 9/25\n",
      "261/261 [==============================] - 0s 181us/step - loss: 0.3716 - acc: 0.8314\n",
      "Epoch 10/25\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3694 - acc: 0.8238\n",
      "Epoch 11/25\n",
      "261/261 [==============================] - 0s 172us/step - loss: 0.3689 - acc: 0.8276\n",
      "Epoch 12/25\n",
      "261/261 [==============================] - 0s 130us/step - loss: 0.3640 - acc: 0.8352\n",
      "Epoch 13/25\n",
      "261/261 [==============================] - 0s 126us/step - loss: 0.3602 - acc: 0.8429\n",
      "Epoch 14/25\n",
      "261/261 [==============================] - 0s 141us/step - loss: 0.3747 - acc: 0.8238\n",
      "Epoch 15/25\n",
      "261/261 [==============================] - 0s 137us/step - loss: 0.3584 - acc: 0.8391\n",
      "Epoch 16/25\n",
      "261/261 [==============================] - 0s 134us/step - loss: 0.3587 - acc: 0.8276\n",
      "Epoch 17/25\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.3601 - acc: 0.8429\n",
      "Epoch 18/25\n",
      "261/261 [==============================] - 0s 147us/step - loss: 0.3538 - acc: 0.8429\n",
      "Epoch 19/25\n",
      "261/261 [==============================] - 0s 125us/step - loss: 0.3512 - acc: 0.8352\n",
      "Epoch 20/25\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.3529 - acc: 0.8314\n",
      "Epoch 21/25\n",
      "261/261 [==============================] - 0s 128us/step - loss: 0.3467 - acc: 0.8314\n",
      "Epoch 22/25\n",
      "261/261 [==============================] - 0s 134us/step - loss: 0.3395 - acc: 0.8582\n",
      "Epoch 23/25\n",
      "261/261 [==============================] - 0s 130us/step - loss: 0.3349 - acc: 0.8506\n",
      "Epoch 24/25\n",
      "261/261 [==============================] - 0s 148us/step - loss: 0.3294 - acc: 0.8506\n",
      "Epoch 25/25\n",
      "261/261 [==============================] - 0s 132us/step - loss: 0.3266 - acc: 0.8582\n",
      "131/131 [==============================] - 0s 4ms/step\n",
      "[CV] ............ batch_size=20, epochs=25, score=0.725, total=   4.1s\n",
      "[CV] batch_size=20, epochs=25 ........................................\n",
      "Epoch 1/25\n",
      "261/261 [==============================] - 2s 7ms/step - loss: 0.6548 - acc: 0.7011\n",
      "Epoch 2/25\n",
      "261/261 [==============================] - 0s 143us/step - loss: 0.5150 - acc: 0.7739\n",
      "Epoch 3/25\n",
      "261/261 [==============================] - 0s 137us/step - loss: 0.4683 - acc: 0.7625\n",
      "Epoch 4/25\n",
      "261/261 [==============================] - 0s 141us/step - loss: 0.4470 - acc: 0.7816\n",
      "Epoch 5/25\n",
      "261/261 [==============================] - 0s 180us/step - loss: 0.4405 - acc: 0.7893\n",
      "Epoch 6/25\n",
      "261/261 [==============================] - 0s 133us/step - loss: 0.4346 - acc: 0.7931\n",
      "Epoch 7/25\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.4263 - acc: 0.8084\n",
      "Epoch 8/25\n",
      "261/261 [==============================] - 0s 140us/step - loss: 0.4251 - acc: 0.8123\n",
      "Epoch 9/25\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.4190 - acc: 0.8084\n",
      "Epoch 10/25\n",
      "261/261 [==============================] - 0s 132us/step - loss: 0.4118 - acc: 0.8084\n",
      "Epoch 11/25\n",
      "261/261 [==============================] - 0s 118us/step - loss: 0.4143 - acc: 0.8199\n",
      "Epoch 12/25\n",
      "261/261 [==============================] - 0s 164us/step - loss: 0.4027 - acc: 0.8161\n",
      "Epoch 13/25\n",
      "261/261 [==============================] - 0s 126us/step - loss: 0.4012 - acc: 0.8238\n",
      "Epoch 14/25\n",
      "261/261 [==============================] - 0s 130us/step - loss: 0.4022 - acc: 0.8391\n",
      "Epoch 15/25\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.3919 - acc: 0.8314\n",
      "Epoch 16/25\n",
      "261/261 [==============================] - 0s 141us/step - loss: 0.3903 - acc: 0.8352\n",
      "Epoch 17/25\n",
      "261/261 [==============================] - 0s 134us/step - loss: 0.3971 - acc: 0.8123\n",
      "Epoch 18/25\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.4051 - acc: 0.8161\n",
      "Epoch 19/25\n",
      "261/261 [==============================] - 0s 125us/step - loss: 0.3884 - acc: 0.8276\n",
      "Epoch 20/25\n",
      "261/261 [==============================] - 0s 143us/step - loss: 0.3808 - acc: 0.8352\n",
      "Epoch 21/25\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.3884 - acc: 0.8238\n",
      "Epoch 22/25\n",
      "261/261 [==============================] - 0s 139us/step - loss: 0.3812 - acc: 0.8238\n",
      "Epoch 23/25\n",
      "261/261 [==============================] - 0s 129us/step - loss: 0.3768 - acc: 0.8391\n",
      "Epoch 24/25\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.3679 - acc: 0.8352\n",
      "Epoch 25/25\n",
      "261/261 [==============================] - 0s 150us/step - loss: 0.3740 - acc: 0.8391\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "[CV] ............ batch_size=20, epochs=25, score=0.748, total=   4.4s\n",
      "[CV] batch_size=20, epochs=25 ........................................\n",
      "Epoch 1/25\n",
      "262/262 [==============================] - 2s 8ms/step - loss: 0.6431 - acc: 0.6527\n",
      "Epoch 2/25\n",
      "262/262 [==============================] - 0s 108us/step - loss: 0.5219 - acc: 0.6908\n",
      "Epoch 3/25\n",
      "262/262 [==============================] - 0s 158us/step - loss: 0.4879 - acc: 0.7366\n",
      "Epoch 4/25\n",
      "262/262 [==============================] - 0s 105us/step - loss: 0.4731 - acc: 0.7557\n",
      "Epoch 5/25\n",
      "262/262 [==============================] - 0s 209us/step - loss: 0.4777 - acc: 0.7710\n",
      "Epoch 6/25\n",
      "262/262 [==============================] - 0s 150us/step - loss: 0.4744 - acc: 0.7786\n",
      "Epoch 7/25\n",
      "262/262 [==============================] - 0s 140us/step - loss: 0.4667 - acc: 0.7634\n",
      "Epoch 8/25\n",
      "262/262 [==============================] - 0s 99us/step - loss: 0.4603 - acc: 0.7672\n",
      "Epoch 9/25\n",
      "262/262 [==============================] - 0s 157us/step - loss: 0.4584 - acc: 0.7634\n",
      "Epoch 10/25\n",
      "262/262 [==============================] - 0s 137us/step - loss: 0.4554 - acc: 0.7710\n",
      "Epoch 11/25\n",
      "262/262 [==============================] - 0s 132us/step - loss: 0.4535 - acc: 0.7824\n",
      "Epoch 12/25\n",
      "262/262 [==============================] - 0s 134us/step - loss: 0.4517 - acc: 0.7786\n",
      "Epoch 13/25\n",
      "262/262 [==============================] - 0s 130us/step - loss: 0.4476 - acc: 0.7977\n",
      "Epoch 14/25\n",
      "262/262 [==============================] - 0s 146us/step - loss: 0.4455 - acc: 0.7786\n",
      "Epoch 15/25\n",
      "262/262 [==============================] - 0s 133us/step - loss: 0.4505 - acc: 0.7824\n",
      "Epoch 16/25\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.4537 - acc: 0.7748\n",
      "Epoch 17/25\n",
      "262/262 [==============================] - 0s 133us/step - loss: 0.4413 - acc: 0.7863\n",
      "Epoch 18/25\n",
      "262/262 [==============================] - 0s 135us/step - loss: 0.4416 - acc: 0.7863\n",
      "Epoch 19/25\n",
      "262/262 [==============================] - 0s 141us/step - loss: 0.4358 - acc: 0.7863\n",
      "Epoch 20/25\n",
      "262/262 [==============================] - 0s 143us/step - loss: 0.4338 - acc: 0.7939\n",
      "Epoch 21/25\n",
      "262/262 [==============================] - 0s 134us/step - loss: 0.4306 - acc: 0.7939\n",
      "Epoch 22/25\n",
      "262/262 [==============================] - 0s 143us/step - loss: 0.4274 - acc: 0.7939\n",
      "Epoch 23/25\n",
      "262/262 [==============================] - 0s 134us/step - loss: 0.4233 - acc: 0.7939\n",
      "Epoch 24/25\n",
      "262/262 [==============================] - 0s 139us/step - loss: 0.4217 - acc: 0.8015\n",
      "Epoch 25/25\n",
      "262/262 [==============================] - 0s 132us/step - loss: 0.4204 - acc: 0.8092\n",
      "130/130 [==============================] - 1s 4ms/step\n",
      "[CV] ............ batch_size=20, epochs=25, score=0.831, total=   4.3s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "261/261 [==============================] - 2s 8ms/step - loss: 0.6626 - acc: 0.7433\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.5137 - acc: 0.7969\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 153us/step - loss: 0.4143 - acc: 0.7969\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 152us/step - loss: 0.3970 - acc: 0.8008\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 127us/step - loss: 0.3866 - acc: 0.8161\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 140us/step - loss: 0.3784 - acc: 0.8123\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 137us/step - loss: 0.3651 - acc: 0.8199\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 211us/step - loss: 0.3634 - acc: 0.8238\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.3526 - acc: 0.8314\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 174us/step - loss: 0.3536 - acc: 0.8314\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 140us/step - loss: 0.3490 - acc: 0.8429\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 130us/step - loss: 0.3391 - acc: 0.8467\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 134us/step - loss: 0.3393 - acc: 0.8467\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 188us/step - loss: 0.3312 - acc: 0.8467\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 107us/step - loss: 0.3295 - acc: 0.8621\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 165us/step - loss: 0.3221 - acc: 0.8659\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 0s 169us/step - loss: 0.3566 - acc: 0.8391\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 0s 162us/step - loss: 0.3286 - acc: 0.8506\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 160us/step - loss: 0.3183 - acc: 0.8621\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 168us/step - loss: 0.3137 - acc: 0.8659\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 163us/step - loss: 0.3127 - acc: 0.8697\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 148us/step - loss: 0.3084 - acc: 0.8659\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 204us/step - loss: 0.3079 - acc: 0.8659\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 174us/step - loss: 0.3037 - acc: 0.8697\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 179us/step - loss: 0.3027 - acc: 0.8659\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 145us/step - loss: 0.3013 - acc: 0.8736\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 118us/step - loss: 0.3015 - acc: 0.8697\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 141us/step - loss: 0.2943 - acc: 0.8659\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 147us/step - loss: 0.2895 - acc: 0.8582\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 0s 158us/step - loss: 0.2950 - acc: 0.8697\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.2967 - acc: 0.8736\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 155us/step - loss: 0.2983 - acc: 0.8697\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 164us/step - loss: 0.2911 - acc: 0.8621\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 150us/step - loss: 0.2821 - acc: 0.8736\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 111us/step - loss: 0.2816 - acc: 0.8812\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 147us/step - loss: 0.2877 - acc: 0.8697\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 173us/step - loss: 0.2790 - acc: 0.8736\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.2765 - acc: 0.8812\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 0s 126us/step - loss: 0.2705 - acc: 0.8889\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.2661 - acc: 0.8889\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 272us/step - loss: 0.2647 - acc: 0.8812\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 179us/step - loss: 0.2651 - acc: 0.8851\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 0s 194us/step - loss: 0.2573 - acc: 0.8927\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 174us/step - loss: 0.2689 - acc: 0.8851\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 181us/step - loss: 0.2661 - acc: 0.8736\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 0s 174us/step - loss: 0.2626 - acc: 0.8774\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 0s 202us/step - loss: 0.2575 - acc: 0.8927\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 0s 215us/step - loss: 0.2672 - acc: 0.8736\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 203us/step - loss: 0.2674 - acc: 0.8889\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 176us/step - loss: 0.2587 - acc: 0.8812\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.733, total=   5.7s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "261/261 [==============================] - 2s 9ms/step - loss: 0.6605 - acc: 0.7318\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 199us/step - loss: 0.5279 - acc: 0.7739\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.4605 - acc: 0.7663\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 140us/step - loss: 0.4488 - acc: 0.7854\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 137us/step - loss: 0.4376 - acc: 0.8123\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 121us/step - loss: 0.4338 - acc: 0.8123\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 147us/step - loss: 0.4349 - acc: 0.7893\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 0s 159us/step - loss: 0.4250 - acc: 0.8008\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 176us/step - loss: 0.4156 - acc: 0.8008\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 266us/step - loss: 0.4214 - acc: 0.7969\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 140us/step - loss: 0.4117 - acc: 0.8046\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 149us/step - loss: 0.4016 - acc: 0.8123\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 145us/step - loss: 0.4035 - acc: 0.8046\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 148us/step - loss: 0.3943 - acc: 0.8084\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 156us/step - loss: 0.3941 - acc: 0.8046\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 192us/step - loss: 0.3862 - acc: 0.8199\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 0s 166us/step - loss: 0.3925 - acc: 0.8123\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 0s 191us/step - loss: 0.3832 - acc: 0.8161\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 177us/step - loss: 0.4337 - acc: 0.8008\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 153us/step - loss: 0.4012 - acc: 0.8161\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 150us/step - loss: 0.3895 - acc: 0.8238\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 161us/step - loss: 0.3765 - acc: 0.8199\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 197us/step - loss: 0.3733 - acc: 0.8314\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 182us/step - loss: 0.3660 - acc: 0.8238\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 185us/step - loss: 0.3836 - acc: 0.8314\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 149us/step - loss: 0.3893 - acc: 0.8276\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 153us/step - loss: 0.3776 - acc: 0.8199\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 136us/step - loss: 0.3672 - acc: 0.8352\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 147us/step - loss: 0.3648 - acc: 0.8314\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 0s 197us/step - loss: 0.3821 - acc: 0.8314\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 183us/step - loss: 0.3660 - acc: 0.8352\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 167us/step - loss: 0.3623 - acc: 0.8352\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 159us/step - loss: 0.3532 - acc: 0.8391\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 175us/step - loss: 0.3519 - acc: 0.8429\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 155us/step - loss: 0.3510 - acc: 0.8467\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 167us/step - loss: 0.3466 - acc: 0.8506\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 189us/step - loss: 0.3567 - acc: 0.8314\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 192us/step - loss: 0.3516 - acc: 0.8582\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 186us/step - loss: 0.3430 - acc: 0.8352\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 155us/step - loss: 0.3451 - acc: 0.8352\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 144us/step - loss: 0.3486 - acc: 0.8429\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 149us/step - loss: 0.3424 - acc: 0.8429\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.3411 - acc: 0.8506\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 251us/step - loss: 0.3401 - acc: 0.8621\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 227us/step - loss: 0.3324 - acc: 0.8506\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 0s 190us/step - loss: 0.3280 - acc: 0.8621\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 0s 175us/step - loss: 0.3232 - acc: 0.8544\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.3216 - acc: 0.8544\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 161us/step - loss: 0.3200 - acc: 0.8736\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.3209 - acc: 0.8544\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.763, total=   6.5s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "262/262 [==============================] - 3s 10ms/step - loss: 0.6815 - acc: 0.6412\n",
      "Epoch 2/50\n",
      "262/262 [==============================] - 0s 164us/step - loss: 0.6137 - acc: 0.7557\n",
      "Epoch 3/50\n",
      "262/262 [==============================] - 0s 162us/step - loss: 0.5327 - acc: 0.7557\n",
      "Epoch 4/50\n",
      "262/262 [==============================] - 0s 174us/step - loss: 0.4915 - acc: 0.7634\n",
      "Epoch 5/50\n",
      "262/262 [==============================] - 0s 169us/step - loss: 0.4768 - acc: 0.7557\n",
      "Epoch 6/50\n",
      "262/262 [==============================] - 0s 162us/step - loss: 0.4668 - acc: 0.7595\n",
      "Epoch 7/50\n",
      "262/262 [==============================] - 0s 155us/step - loss: 0.4554 - acc: 0.7481\n",
      "Epoch 8/50\n",
      "262/262 [==============================] - 0s 174us/step - loss: 0.4444 - acc: 0.7748\n",
      "Epoch 9/50\n",
      "262/262 [==============================] - 0s 179us/step - loss: 0.4302 - acc: 0.7901\n",
      "Epoch 10/50\n",
      "262/262 [==============================] - 0s 152us/step - loss: 0.4379 - acc: 0.7863\n",
      "Epoch 11/50\n",
      "262/262 [==============================] - 0s 200us/step - loss: 0.4299 - acc: 0.7748\n",
      "Epoch 12/50\n",
      "262/262 [==============================] - 0s 226us/step - loss: 0.4193 - acc: 0.8092\n",
      "Epoch 13/50\n",
      "262/262 [==============================] - 0s 134us/step - loss: 0.4203 - acc: 0.7863\n",
      "Epoch 14/50\n",
      "262/262 [==============================] - 0s 346us/step - loss: 0.4330 - acc: 0.7901\n",
      "Epoch 15/50\n",
      "262/262 [==============================] - 0s 188us/step - loss: 0.4148 - acc: 0.7939\n",
      "Epoch 16/50\n",
      "262/262 [==============================] - 0s 222us/step - loss: 0.4113 - acc: 0.8244\n",
      "Epoch 17/50\n",
      "262/262 [==============================] - 0s 217us/step - loss: 0.4064 - acc: 0.8092\n",
      "Epoch 18/50\n",
      "262/262 [==============================] - 0s 179us/step - loss: 0.4040 - acc: 0.8168\n",
      "Epoch 19/50\n",
      "262/262 [==============================] - 0s 140us/step - loss: 0.4043 - acc: 0.8053\n",
      "Epoch 20/50\n",
      "262/262 [==============================] - 0s 218us/step - loss: 0.4045 - acc: 0.8130\n",
      "Epoch 21/50\n",
      "262/262 [==============================] - 0s 227us/step - loss: 0.4081 - acc: 0.8244\n",
      "Epoch 22/50\n",
      "262/262 [==============================] - 0s 159us/step - loss: 0.3966 - acc: 0.8092\n",
      "Epoch 23/50\n",
      "262/262 [==============================] - 0s 147us/step - loss: 0.4003 - acc: 0.8130\n",
      "Epoch 24/50\n",
      "262/262 [==============================] - 0s 148us/step - loss: 0.3975 - acc: 0.8244\n",
      "Epoch 25/50\n",
      "262/262 [==============================] - 0s 142us/step - loss: 0.3956 - acc: 0.8206\n",
      "Epoch 26/50\n",
      "262/262 [==============================] - 0s 162us/step - loss: 0.3869 - acc: 0.8206\n",
      "Epoch 27/50\n",
      "262/262 [==============================] - 0s 161us/step - loss: 0.3891 - acc: 0.8321\n",
      "Epoch 28/50\n",
      "262/262 [==============================] - 0s 167us/step - loss: 0.3817 - acc: 0.8359\n",
      "Epoch 29/50\n",
      "262/262 [==============================] - 0s 195us/step - loss: 0.3769 - acc: 0.8435\n",
      "Epoch 30/50\n",
      "262/262 [==============================] - 0s 165us/step - loss: 0.3813 - acc: 0.8359\n",
      "Epoch 31/50\n",
      "262/262 [==============================] - 0s 187us/step - loss: 0.3779 - acc: 0.8321\n",
      "Epoch 32/50\n",
      "262/262 [==============================] - 0s 248us/step - loss: 0.3689 - acc: 0.8473\n",
      "Epoch 33/50\n",
      "262/262 [==============================] - 0s 198us/step - loss: 0.3694 - acc: 0.8473\n",
      "Epoch 34/50\n",
      "262/262 [==============================] - 0s 258us/step - loss: 0.3675 - acc: 0.8511\n",
      "Epoch 35/50\n",
      "262/262 [==============================] - 0s 154us/step - loss: 0.3640 - acc: 0.8473\n",
      "Epoch 36/50\n",
      "262/262 [==============================] - 0s 194us/step - loss: 0.3609 - acc: 0.8550\n",
      "Epoch 37/50\n",
      "262/262 [==============================] - 0s 194us/step - loss: 0.3564 - acc: 0.8588\n",
      "Epoch 38/50\n",
      "262/262 [==============================] - 0s 156us/step - loss: 0.3615 - acc: 0.8473\n",
      "Epoch 39/50\n",
      "262/262 [==============================] - 0s 165us/step - loss: 0.3630 - acc: 0.8435\n",
      "Epoch 40/50\n",
      "262/262 [==============================] - 0s 161us/step - loss: 0.3684 - acc: 0.8473\n",
      "Epoch 41/50\n",
      "262/262 [==============================] - 0s 213us/step - loss: 0.3612 - acc: 0.8435\n",
      "Epoch 42/50\n",
      "262/262 [==============================] - 0s 178us/step - loss: 0.3585 - acc: 0.8511\n",
      "Epoch 43/50\n",
      "262/262 [==============================] - 0s 147us/step - loss: 0.3560 - acc: 0.8397\n",
      "Epoch 44/50\n",
      "262/262 [==============================] - 0s 144us/step - loss: 0.3644 - acc: 0.8435\n",
      "Epoch 45/50\n",
      "262/262 [==============================] - 0s 169us/step - loss: 0.3459 - acc: 0.8626\n",
      "Epoch 46/50\n",
      "262/262 [==============================] - 0s 136us/step - loss: 0.3495 - acc: 0.8473\n",
      "Epoch 47/50\n",
      "262/262 [==============================] - 0s 145us/step - loss: 0.3470 - acc: 0.8435\n",
      "Epoch 48/50\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.3386 - acc: 0.8588\n",
      "Epoch 49/50\n",
      "262/262 [==============================] - 0s 199us/step - loss: 0.3412 - acc: 0.8702\n",
      "Epoch 50/50\n",
      "262/262 [==============================] - 0s 192us/step - loss: 0.3489 - acc: 0.8397\n",
      "130/130 [==============================] - 1s 5ms/step\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.831, total=   6.9s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "261/261 [==============================] - 2s 9ms/step - loss: 0.6886 - acc: 0.6130\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.6688 - acc: 0.7663\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 91us/step - loss: 0.6387 - acc: 0.7701\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.5858 - acc: 0.7893\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.5098 - acc: 0.7969\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.4452 - acc: 0.7893\n",
      "Epoch 7/10\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.4118 - acc: 0.7893\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 89us/step - loss: 0.3944 - acc: 0.8008\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.3847 - acc: 0.8084\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.3760 - acc: 0.8161\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.733, total=   4.5s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "261/261 [==============================] - 2s 9ms/step - loss: 0.6720 - acc: 0.6360\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.6003 - acc: 0.6513\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.5198 - acc: 0.6513\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 78us/step - loss: 0.4907 - acc: 0.7548\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.4812 - acc: 0.8008\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 94us/step - loss: 0.4610 - acc: 0.8161\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 81us/step - loss: 0.4409 - acc: 0.8008\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 59us/step - loss: 0.4332 - acc: 0.7931\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - 0s 72us/step - loss: 0.4244 - acc: 0.8046\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 80us/step - loss: 0.4151 - acc: 0.8046\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.763, total=   4.2s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "262/262 [==============================] - 2s 9ms/step - loss: 0.6841 - acc: 0.5878\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 0s 47us/step - loss: 0.6504 - acc: 0.6527\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 0s 94us/step - loss: 0.5990 - acc: 0.6527\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.5441 - acc: 0.6527\n",
      "Epoch 5/10\n",
      "262/262 [==============================] - 0s 82us/step - loss: 0.5051 - acc: 0.7176\n",
      "Epoch 6/10\n",
      "262/262 [==============================] - 0s 155us/step - loss: 0.4869 - acc: 0.7328\n",
      "Epoch 7/10\n",
      "262/262 [==============================] - 0s 81us/step - loss: 0.4723 - acc: 0.7710\n",
      "Epoch 8/10\n",
      "262/262 [==============================] - 0s 51us/step - loss: 0.4670 - acc: 0.7748\n",
      "Epoch 9/10\n",
      "262/262 [==============================] - 0s 91us/step - loss: 0.4649 - acc: 0.7672\n",
      "Epoch 10/10\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.4616 - acc: 0.7710\n",
      "130/130 [==============================] - 1s 5ms/step\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.815, total=   4.2s\n",
      "[CV] batch_size=40, epochs=25 ........................................\n",
      "Epoch 1/25\n",
      "261/261 [==============================] - 2s 9ms/step - loss: 0.6850 - acc: 0.6973\n",
      "Epoch 2/25\n",
      "261/261 [==============================] - 0s 53us/step - loss: 0.6538 - acc: 0.7663\n",
      "Epoch 3/25\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.6066 - acc: 0.7854\n",
      "Epoch 4/25\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.5391 - acc: 0.7931\n",
      "Epoch 5/25\n",
      "261/261 [==============================] - 0s 56us/step - loss: 0.4794 - acc: 0.7931\n",
      "Epoch 6/25\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.4285 - acc: 0.7893\n",
      "Epoch 7/25\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.4013 - acc: 0.7969\n",
      "Epoch 8/25\n",
      "261/261 [==============================] - 0s 95us/step - loss: 0.3868 - acc: 0.8084\n",
      "Epoch 9/25\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.3773 - acc: 0.8161\n",
      "Epoch 10/25\n",
      "261/261 [==============================] - 0s 55us/step - loss: 0.3720 - acc: 0.8161\n",
      "Epoch 11/25\n",
      "261/261 [==============================] - 0s 82us/step - loss: 0.3670 - acc: 0.8161\n",
      "Epoch 12/25\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.3627 - acc: 0.8238\n",
      "Epoch 13/25\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.3560 - acc: 0.8314\n",
      "Epoch 14/25\n",
      "261/261 [==============================] - 0s 107us/step - loss: 0.3508 - acc: 0.8352\n",
      "Epoch 15/25\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.3466 - acc: 0.8314\n",
      "Epoch 16/25\n",
      "261/261 [==============================] - 0s 101us/step - loss: 0.3462 - acc: 0.8429\n",
      "Epoch 17/25\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.3407 - acc: 0.8391\n",
      "Epoch 18/25\n",
      "261/261 [==============================] - 0s 80us/step - loss: 0.3377 - acc: 0.8506\n",
      "Epoch 19/25\n",
      "261/261 [==============================] - 0s 76us/step - loss: 0.3344 - acc: 0.8544\n",
      "Epoch 20/25\n",
      "261/261 [==============================] - 0s 80us/step - loss: 0.3302 - acc: 0.8544\n",
      "Epoch 21/25\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.3267 - acc: 0.8506\n",
      "Epoch 22/25\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.3211 - acc: 0.8582\n",
      "Epoch 23/25\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.3169 - acc: 0.8506\n",
      "Epoch 24/25\n",
      "261/261 [==============================] - 0s 101us/step - loss: 0.3165 - acc: 0.8582\n",
      "Epoch 25/25\n",
      "261/261 [==============================] - 0s 40us/step - loss: 0.3126 - acc: 0.8582\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "[CV] ............ batch_size=40, epochs=25, score=0.748, total=   4.7s\n",
      "[CV] batch_size=40, epochs=25 ........................................\n",
      "Epoch 1/25\n",
      "261/261 [==============================] - 2s 9ms/step - loss: 0.6802 - acc: 0.6437\n",
      "Epoch 2/25\n",
      "261/261 [==============================] - 0s 47us/step - loss: 0.6343 - acc: 0.6667\n",
      "Epoch 3/25\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.5660 - acc: 0.7625\n",
      "Epoch 4/25\n",
      "261/261 [==============================] - 0s 82us/step - loss: 0.5029 - acc: 0.7778\n",
      "Epoch 5/25\n",
      "261/261 [==============================] - 0s 84us/step - loss: 0.4661 - acc: 0.7816\n",
      "Epoch 6/25\n",
      "261/261 [==============================] - 0s 89us/step - loss: 0.4511 - acc: 0.7969\n",
      "Epoch 7/25\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.4433 - acc: 0.7893\n",
      "Epoch 8/25\n",
      "261/261 [==============================] - 0s 86us/step - loss: 0.4365 - acc: 0.7816\n",
      "Epoch 9/25\n",
      "261/261 [==============================] - 0s 86us/step - loss: 0.4322 - acc: 0.7931\n",
      "Epoch 10/25\n",
      "261/261 [==============================] - 0s 95us/step - loss: 0.4287 - acc: 0.7931\n",
      "Epoch 11/25\n",
      "261/261 [==============================] - 0s 93us/step - loss: 0.4221 - acc: 0.8123\n",
      "Epoch 12/25\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.4202 - acc: 0.8123\n",
      "Epoch 13/25\n",
      "261/261 [==============================] - 0s 74us/step - loss: 0.4170 - acc: 0.8199\n",
      "Epoch 14/25\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.4145 - acc: 0.8123\n",
      "Epoch 15/25\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.4143 - acc: 0.8199\n",
      "Epoch 16/25\n",
      "261/261 [==============================] - 0s 74us/step - loss: 0.4138 - acc: 0.8123\n",
      "Epoch 17/25\n",
      "261/261 [==============================] - 0s 89us/step - loss: 0.4087 - acc: 0.8199\n",
      "Epoch 18/25\n",
      "261/261 [==============================] - 0s 103us/step - loss: 0.4052 - acc: 0.8199\n",
      "Epoch 19/25\n",
      "261/261 [==============================] - 0s 87us/step - loss: 0.4033 - acc: 0.8161\n",
      "Epoch 20/25\n",
      "261/261 [==============================] - 0s 78us/step - loss: 0.4014 - acc: 0.8161\n",
      "Epoch 21/25\n",
      "261/261 [==============================] - 0s 82us/step - loss: 0.4002 - acc: 0.8084\n",
      "Epoch 22/25\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.3955 - acc: 0.8238\n",
      "Epoch 23/25\n",
      "261/261 [==============================] - 0s 95us/step - loss: 0.3914 - acc: 0.8238\n",
      "Epoch 24/25\n",
      "261/261 [==============================] - 0s 122us/step - loss: 0.3897 - acc: 0.8276\n",
      "Epoch 25/25\n",
      "261/261 [==============================] - 0s 51us/step - loss: 0.3907 - acc: 0.8352\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "[CV] ............ batch_size=40, epochs=25, score=0.779, total=   4.6s\n",
      "[CV] batch_size=40, epochs=25 ........................................\n",
      "Epoch 1/25\n",
      "262/262 [==============================] - 3s 11ms/step - loss: 0.6907 - acc: 0.5725\n",
      "Epoch 2/25\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.6817 - acc: 0.6527\n",
      "Epoch 3/25\n",
      "262/262 [==============================] - 0s 81us/step - loss: 0.6735 - acc: 0.6527\n",
      "Epoch 4/25\n",
      "262/262 [==============================] - 0s 94us/step - loss: 0.6629 - acc: 0.6527\n",
      "Epoch 5/25\n",
      "262/262 [==============================] - 0s 93us/step - loss: 0.6428 - acc: 0.7290\n",
      "Epoch 6/25\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.6222 - acc: 0.7366\n",
      "Epoch 7/25\n",
      "262/262 [==============================] - 0s 77us/step - loss: 0.5992 - acc: 0.7366\n",
      "Epoch 8/25\n",
      "262/262 [==============================] - 0s 89us/step - loss: 0.5860 - acc: 0.7595\n",
      "Epoch 9/25\n",
      "262/262 [==============================] - 0s 88us/step - loss: 0.5761 - acc: 0.7557\n",
      "Epoch 10/25\n",
      "262/262 [==============================] - 0s 79us/step - loss: 0.5638 - acc: 0.7672\n",
      "Epoch 11/25\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.5530 - acc: 0.7595\n",
      "Epoch 12/25\n",
      "262/262 [==============================] - 0s 96us/step - loss: 0.5443 - acc: 0.7634\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 0s 88us/step - loss: 0.5369 - acc: 0.7634\n",
      "Epoch 14/25\n",
      "262/262 [==============================] - 0s 94us/step - loss: 0.5264 - acc: 0.7824\n",
      "Epoch 15/25\n",
      "262/262 [==============================] - 0s 89us/step - loss: 0.5216 - acc: 0.7977\n",
      "Epoch 16/25\n",
      "262/262 [==============================] - 0s 125us/step - loss: 0.5167 - acc: 0.7824\n",
      "Epoch 17/25\n",
      "262/262 [==============================] - 0s 104us/step - loss: 0.5060 - acc: 0.7824\n",
      "Epoch 18/25\n",
      "262/262 [==============================] - 0s 108us/step - loss: 0.5021 - acc: 0.7901\n",
      "Epoch 19/25\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.4960 - acc: 0.7863\n",
      "Epoch 20/25\n",
      "262/262 [==============================] - 0s 99us/step - loss: 0.4905 - acc: 0.7863\n",
      "Epoch 21/25\n",
      "262/262 [==============================] - 0s 79us/step - loss: 0.4851 - acc: 0.7977\n",
      "Epoch 22/25\n",
      "262/262 [==============================] - 0s 84us/step - loss: 0.4810 - acc: 0.7977\n",
      "Epoch 23/25\n",
      "262/262 [==============================] - 0s 99us/step - loss: 0.4756 - acc: 0.7939\n",
      "Epoch 24/25\n",
      "262/262 [==============================] - 0s 129us/step - loss: 0.4705 - acc: 0.7939\n",
      "Epoch 25/25\n",
      "262/262 [==============================] - 0s 100us/step - loss: 0.4670 - acc: 0.7863\n",
      "130/130 [==============================] - 1s 6ms/step\n",
      "[CV] ............ batch_size=40, epochs=25, score=0.838, total=   5.2s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "261/261 [==============================] - 3s 11ms/step - loss: 0.6692 - acc: 0.7203\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 61us/step - loss: 0.6004 - acc: 0.7625\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.5095 - acc: 0.7739\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 91us/step - loss: 0.4493 - acc: 0.7778\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 93us/step - loss: 0.4169 - acc: 0.7969\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 118us/step - loss: 0.3987 - acc: 0.8008\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 95us/step - loss: 0.3921 - acc: 0.8161\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.3847 - acc: 0.8161\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 91us/step - loss: 0.3774 - acc: 0.8161\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.3715 - acc: 0.8314\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.3670 - acc: 0.8314\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 82us/step - loss: 0.3642 - acc: 0.8352\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 94us/step - loss: 0.3623 - acc: 0.8467\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.3593 - acc: 0.8429\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 84us/step - loss: 0.3566 - acc: 0.8429\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 93us/step - loss: 0.3560 - acc: 0.8467\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 0s 84us/step - loss: 0.3521 - acc: 0.8429\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.3503 - acc: 0.8429\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.3496 - acc: 0.8429\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.3481 - acc: 0.8314\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.3457 - acc: 0.8391\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 74us/step - loss: 0.3434 - acc: 0.8544\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 93us/step - loss: 0.3420 - acc: 0.8544\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.3398 - acc: 0.8467\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 49us/step - loss: 0.3373 - acc: 0.8391\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.3334 - acc: 0.8429\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 61us/step - loss: 0.3346 - acc: 0.8544\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 201us/step - loss: 0.3295 - acc: 0.8506\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.3276 - acc: 0.8506\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3257 - acc: 0.8467\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 86us/step - loss: 0.3239 - acc: 0.8544\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 79us/step - loss: 0.3263 - acc: 0.8391\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.3210 - acc: 0.8506\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 72us/step - loss: 0.3187 - acc: 0.8582\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 67us/step - loss: 0.3181 - acc: 0.8582\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 76us/step - loss: 0.3158 - acc: 0.8621\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.3161 - acc: 0.8582\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 89us/step - loss: 0.3135 - acc: 0.8544\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 0s 145us/step - loss: 0.3126 - acc: 0.8544\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 99us/step - loss: 0.3104 - acc: 0.8506\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.3110 - acc: 0.8544\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.3088 - acc: 0.8582\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 0s 103us/step - loss: 0.3065 - acc: 0.8621\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 82us/step - loss: 0.3048 - acc: 0.8582\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 107us/step - loss: 0.3026 - acc: 0.8582\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.2998 - acc: 0.8621\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 0s 89us/step - loss: 0.2980 - acc: 0.8697\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 0s 123us/step - loss: 0.2963 - acc: 0.8621\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 99us/step - loss: 0.2932 - acc: 0.8697\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 82us/step - loss: 0.2931 - acc: 0.8659\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.695, total=   6.3s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "261/261 [==============================] - 3s 10ms/step - loss: 0.6817 - acc: 0.6935\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.6374 - acc: 0.7739\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 151us/step - loss: 0.5669 - acc: 0.7854\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 104us/step - loss: 0.4891 - acc: 0.7739\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 70us/step - loss: 0.4534 - acc: 0.7778\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.4470 - acc: 0.7816\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.4391 - acc: 0.7893\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.4281 - acc: 0.8046\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 85us/step - loss: 0.4254 - acc: 0.8084\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 94us/step - loss: 0.4221 - acc: 0.8084\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 63us/step - loss: 0.4195 - acc: 0.8084\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 114us/step - loss: 0.4194 - acc: 0.8199\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 78us/step - loss: 0.4131 - acc: 0.8123\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 108us/step - loss: 0.4133 - acc: 0.8161\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.4100 - acc: 0.8123\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 99us/step - loss: 0.4092 - acc: 0.8276\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 0s 99us/step - loss: 0.4029 - acc: 0.8276\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 0s 107us/step - loss: 0.4052 - acc: 0.8238\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 112us/step - loss: 0.4025 - acc: 0.8199\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 97us/step - loss: 0.4017 - acc: 0.8199\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 80us/step - loss: 0.3968 - acc: 0.8238\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 101us/step - loss: 0.3965 - acc: 0.8199\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 118us/step - loss: 0.3944 - acc: 0.8161\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.3979 - acc: 0.8238\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 102us/step - loss: 0.3897 - acc: 0.8314\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 122us/step - loss: 0.3882 - acc: 0.8199\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 84us/step - loss: 0.3869 - acc: 0.8238\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 99us/step - loss: 0.3850 - acc: 0.8199\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 116us/step - loss: 0.3834 - acc: 0.8238\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3845 - acc: 0.8199\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.3756 - acc: 0.8276\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 71us/step - loss: 0.3785 - acc: 0.8238\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 74us/step - loss: 0.3744 - acc: 0.8276\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 94us/step - loss: 0.3713 - acc: 0.8352\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.3690 - acc: 0.8276\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 90us/step - loss: 0.3694 - acc: 0.8276\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 98us/step - loss: 0.3703 - acc: 0.8199\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.3634 - acc: 0.8238\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 0s 106us/step - loss: 0.3634 - acc: 0.8352\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 91us/step - loss: 0.3602 - acc: 0.8238\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 83us/step - loss: 0.3642 - acc: 0.8161\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 91us/step - loss: 0.3669 - acc: 0.8276\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 0s 148us/step - loss: 0.3528 - acc: 0.8429\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.3585 - acc: 0.8429\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 135us/step - loss: 0.3467 - acc: 0.8467\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.3469 - acc: 0.8467\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.3403 - acc: 0.8544\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 0s 97us/step - loss: 0.3381 - acc: 0.8467\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 91us/step - loss: 0.3367 - acc: 0.8429\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.3331 - acc: 0.8467\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.763, total=   5.8s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "262/262 [==============================] - 3s 11ms/step - loss: 0.6750 - acc: 0.6527\n",
      "Epoch 2/50\n",
      "262/262 [==============================] - 0s 95us/step - loss: 0.6068 - acc: 0.6679\n",
      "Epoch 3/50\n",
      "262/262 [==============================] - 0s 78us/step - loss: 0.5327 - acc: 0.7023\n",
      "Epoch 4/50\n",
      "262/262 [==============================] - 0s 88us/step - loss: 0.4925 - acc: 0.7519\n",
      "Epoch 5/50\n",
      "262/262 [==============================] - 0s 85us/step - loss: 0.4787 - acc: 0.7557\n",
      "Epoch 6/50\n",
      "262/262 [==============================] - 0s 94us/step - loss: 0.4730 - acc: 0.7557\n",
      "Epoch 7/50\n",
      "262/262 [==============================] - 0s 86us/step - loss: 0.4707 - acc: 0.7519\n",
      "Epoch 8/50\n",
      "262/262 [==============================] - 0s 91us/step - loss: 0.4708 - acc: 0.7672\n",
      "Epoch 9/50\n",
      "262/262 [==============================] - 0s 95us/step - loss: 0.4638 - acc: 0.7786\n",
      "Epoch 10/50\n",
      "262/262 [==============================] - 0s 96us/step - loss: 0.4609 - acc: 0.7710\n",
      "Epoch 11/50\n",
      "262/262 [==============================] - 0s 98us/step - loss: 0.4582 - acc: 0.7634\n",
      "Epoch 12/50\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.4553 - acc: 0.7672\n",
      "Epoch 13/50\n",
      "262/262 [==============================] - 0s 83us/step - loss: 0.4535 - acc: 0.7710\n",
      "Epoch 14/50\n",
      "262/262 [==============================] - 0s 88us/step - loss: 0.4508 - acc: 0.7672\n",
      "Epoch 15/50\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.4486 - acc: 0.7672\n",
      "Epoch 16/50\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.4457 - acc: 0.7710\n",
      "Epoch 17/50\n",
      "262/262 [==============================] - 0s 102us/step - loss: 0.4429 - acc: 0.7748\n",
      "Epoch 18/50\n",
      "262/262 [==============================] - 0s 112us/step - loss: 0.4422 - acc: 0.7748\n",
      "Epoch 19/50\n",
      "262/262 [==============================] - 0s 93us/step - loss: 0.4387 - acc: 0.7672\n",
      "Epoch 20/50\n",
      "262/262 [==============================] - 0s 83us/step - loss: 0.4380 - acc: 0.7748\n",
      "Epoch 21/50\n",
      "262/262 [==============================] - 0s 74us/step - loss: 0.4344 - acc: 0.7786\n",
      "Epoch 22/50\n",
      "262/262 [==============================] - 0s 109us/step - loss: 0.4312 - acc: 0.7863\n",
      "Epoch 23/50\n",
      "262/262 [==============================] - 0s 85us/step - loss: 0.4301 - acc: 0.7786\n",
      "Epoch 24/50\n",
      "262/262 [==============================] - 0s 89us/step - loss: 0.4239 - acc: 0.7863\n",
      "Epoch 25/50\n",
      "262/262 [==============================] - 0s 81us/step - loss: 0.4220 - acc: 0.7863\n",
      "Epoch 26/50\n",
      "262/262 [==============================] - 0s 85us/step - loss: 0.4177 - acc: 0.7901\n",
      "Epoch 27/50\n",
      "262/262 [==============================] - 0s 109us/step - loss: 0.4142 - acc: 0.7939\n",
      "Epoch 28/50\n",
      "262/262 [==============================] - 0s 88us/step - loss: 0.4100 - acc: 0.8092\n",
      "Epoch 29/50\n",
      "262/262 [==============================] - 0s 99us/step - loss: 0.4033 - acc: 0.8206\n",
      "Epoch 30/50\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.3981 - acc: 0.8244\n",
      "Epoch 31/50\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.3930 - acc: 0.8244\n",
      "Epoch 32/50\n",
      "262/262 [==============================] - 0s 81us/step - loss: 0.3892 - acc: 0.8282\n",
      "Epoch 33/50\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.3893 - acc: 0.8282\n",
      "Epoch 34/50\n",
      "262/262 [==============================] - 0s 97us/step - loss: 0.3849 - acc: 0.8321\n",
      "Epoch 35/50\n",
      "262/262 [==============================] - 0s 78us/step - loss: 0.3828 - acc: 0.8168\n",
      "Epoch 36/50\n",
      "262/262 [==============================] - 0s 100us/step - loss: 0.3791 - acc: 0.8359\n",
      "Epoch 37/50\n",
      "262/262 [==============================] - 0s 82us/step - loss: 0.3761 - acc: 0.8282\n",
      "Epoch 38/50\n",
      "262/262 [==============================] - 0s 76us/step - loss: 0.3782 - acc: 0.8244\n",
      "Epoch 39/50\n",
      "262/262 [==============================] - 0s 89us/step - loss: 0.3710 - acc: 0.8359\n",
      "Epoch 40/50\n",
      "262/262 [==============================] - 0s 84us/step - loss: 0.3708 - acc: 0.8282\n",
      "Epoch 41/50\n",
      "262/262 [==============================] - 0s 91us/step - loss: 0.3661 - acc: 0.8435\n",
      "Epoch 42/50\n",
      "262/262 [==============================] - 0s 83us/step - loss: 0.3676 - acc: 0.8435\n",
      "Epoch 43/50\n",
      "262/262 [==============================] - 0s 95us/step - loss: 0.3600 - acc: 0.8359\n",
      "Epoch 44/50\n",
      "262/262 [==============================] - 0s 90us/step - loss: 0.3656 - acc: 0.8282\n",
      "Epoch 45/50\n",
      "262/262 [==============================] - 0s 72us/step - loss: 0.3541 - acc: 0.8359\n",
      "Epoch 46/50\n",
      "262/262 [==============================] - 0s 95us/step - loss: 0.3595 - acc: 0.8435\n",
      "Epoch 47/50\n",
      "262/262 [==============================] - 0s 86us/step - loss: 0.3583 - acc: 0.8321\n",
      "Epoch 48/50\n",
      "262/262 [==============================] - 0s 103us/step - loss: 0.3492 - acc: 0.8397\n",
      "Epoch 49/50\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.3533 - acc: 0.8359\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 0s 86us/step - loss: 0.3556 - acc: 0.8435\n",
      "130/130 [==============================] - 1s 6ms/step\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.854, total=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  2.2min finished\n",
      "C:\\Users\\Dipto\\Anaconda33\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "392/392 [==============================] - 3s 7ms/step - loss: 0.6706 - acc: 0.6556\n",
      "Epoch 2/25\n",
      "392/392 [==============================] - 0s 73us/step - loss: 0.5914 - acc: 0.7372\n",
      "Epoch 3/25\n",
      "392/392 [==============================] - 0s 76us/step - loss: 0.5012 - acc: 0.7704\n",
      "Epoch 4/25\n",
      "392/392 [==============================] - 0s 69us/step - loss: 0.4591 - acc: 0.7704\n",
      "Epoch 5/25\n",
      "392/392 [==============================] - 0s 81us/step - loss: 0.4522 - acc: 0.7653\n",
      "Epoch 6/25\n",
      "392/392 [==============================] - 0s 70us/step - loss: 0.4393 - acc: 0.7806\n",
      "Epoch 7/25\n",
      "392/392 [==============================] - 0s 77us/step - loss: 0.4354 - acc: 0.7985\n",
      "Epoch 8/25\n",
      "392/392 [==============================] - 0s 78us/step - loss: 0.4325 - acc: 0.7755\n",
      "Epoch 9/25\n",
      "392/392 [==============================] - 0s 74us/step - loss: 0.4278 - acc: 0.7806\n",
      "Epoch 10/25\n",
      "392/392 [==============================] - 0s 76us/step - loss: 0.4297 - acc: 0.7883\n",
      "Epoch 11/25\n",
      "392/392 [==============================] - 0s 85us/step - loss: 0.4226 - acc: 0.7934\n",
      "Epoch 12/25\n",
      "392/392 [==============================] - 0s 77us/step - loss: 0.4198 - acc: 0.7934\n",
      "Epoch 13/25\n",
      "392/392 [==============================] - 0s 76us/step - loss: 0.4171 - acc: 0.7985\n",
      "Epoch 14/25\n",
      "392/392 [==============================] - 0s 77us/step - loss: 0.4145 - acc: 0.7959\n",
      "Epoch 15/25\n",
      "392/392 [==============================] - 0s 76us/step - loss: 0.4115 - acc: 0.8010\n",
      "Epoch 16/25\n",
      "392/392 [==============================] - 0s 76us/step - loss: 0.4093 - acc: 0.7985\n",
      "Epoch 17/25\n",
      "392/392 [==============================] - 0s 71us/step - loss: 0.4065 - acc: 0.7959\n",
      "Epoch 18/25\n",
      "392/392 [==============================] - 0s 98us/step - loss: 0.4045 - acc: 0.8087\n",
      "Epoch 19/25\n",
      "392/392 [==============================] - 0s 101us/step - loss: 0.4021 - acc: 0.8061\n",
      "Epoch 20/25\n",
      "392/392 [==============================] - 0s 76us/step - loss: 0.3984 - acc: 0.8163\n",
      "Epoch 21/25\n",
      "392/392 [==============================] - 0s 64us/step - loss: 0.3975 - acc: 0.8061\n",
      "Epoch 22/25\n",
      "392/392 [==============================] - 0s 73us/step - loss: 0.3928 - acc: 0.8138\n",
      "Epoch 23/25\n",
      "392/392 [==============================] - 0s 70us/step - loss: 0.3922 - acc: 0.8163\n",
      "Epoch 24/25\n",
      "392/392 [==============================] - 0s 79us/step - loss: 0.3878 - acc: 0.8189\n",
      "Epoch 25/25\n",
      "392/392 [==============================] - 0s 79us/step - loss: 0.3865 - acc: 0.8189\n",
      "Best Score 0.7882653080991336 , using {'batch_size': 40, 'epochs': 25} \n",
      "0.775510200736474 , 0.039421720663473526 with : {'batch_size': 10, 'epochs': 10} \n",
      "0.778061221752848 , 0.052703928289198364 with : {'batch_size': 10, 'epochs': 25} \n",
      "0.7831632622650692 , 0.033678633527928055 with : {'batch_size': 10, 'epochs': 50} \n",
      "0.7780612267705859 , 0.02647522554607286 with : {'batch_size': 20, 'epochs': 10} \n",
      "0.7678571460502488 , 0.04529337147792291 with : {'batch_size': 20, 'epochs': 25} \n",
      "0.7755102072747386 , 0.040876799193878245 with : {'batch_size': 20, 'epochs': 50} \n",
      "0.7704081622009374 , 0.03405154454075605 with : {'batch_size': 40, 'epochs': 10} \n",
      "0.7882653080991336 , 0.03749668250365864 with : {'batch_size': 40, 'epochs': 25} \n",
      "0.7704081649378854 , 0.06513869988003138 with : {'batch_size': 40, 'epochs': 50} \n"
     ]
    }
   ],
   "source": [
    "# function to define Model\n",
    "seed=6\n",
    "np.random.seed(seed)\n",
    "def  model_create_new():\n",
    "    #Create Model\n",
    "    model=Sequential()\n",
    "    model.add(Dense(8,input_dim=8,kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dense(4,input_dim=8,kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    #Compile The Model\n",
    "    adam = Adam(lr =0.01)\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_new= KerasClassifier(build_fn= model_create_new,verbose=1)\n",
    "\n",
    "# Define Grid Search\n",
    "\n",
    "batch_size=[10,20,40]\n",
    "epochs=[10,25,50]\n",
    "\n",
    "# make a dictionary for gridSearch\n",
    "param_grid=dict(batch_size=batch_size,epochs=epochs)\n",
    "\n",
    "#Build The Grid Search\n",
    "grid=GridSearchCV(estimator=model_new,param_grid=param_grid,cv=KFold(random_state=seed),verbose=5)\n",
    "\n",
    "grid_results=grid.fit(Xfin,y)\n",
    "\n",
    "# Summarise Results\n",
    "\n",
    "print(\"Best Score {} , using {} \".format(grid_results.best_score_,grid_results.best_params_))\n",
    "mean=grid_results.cv_results_['mean_test_score']\n",
    "stds=grid_results.cv_results_['std_test_score']\n",
    "params=grid_results.cv_results_['params']\n",
    "\n",
    "for mean,stdev,params in zip(mean,stds,params):\n",
    "    print(\"{} , {} with : {} \".format(mean,stdev,params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Droupot Rate and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] dropout_rate=0.0, learn_rate=0.1 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... dropout_rate=0.0, learn_rate=0.1, score=0.771, total=   5.8s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.1 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... dropout_rate=0.0, learn_rate=0.1, score=0.756, total=   5.9s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.1 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   11.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... dropout_rate=0.0, learn_rate=0.1, score=0.808, total=   6.4s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.01 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   18.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... dropout_rate=0.0, learn_rate=0.01, score=0.756, total=   6.1s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.01 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   24.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... dropout_rate=0.0, learn_rate=0.01, score=0.771, total=   5.9s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.01 ...............................\n",
      "[CV] ... dropout_rate=0.0, learn_rate=0.01, score=0.862, total=   6.0s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.001 ..............................\n",
      "[CV] .. dropout_rate=0.0, learn_rate=0.001, score=0.733, total=   7.2s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.001 ..............................\n",
      "[CV] .. dropout_rate=0.0, learn_rate=0.001, score=0.748, total=   6.4s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.001 ..............................\n",
      "[CV] .. dropout_rate=0.0, learn_rate=0.001, score=0.700, total=   6.6s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.1 ................................\n",
      "WARNING:tensorflow:From C:\\Users\\Dipto\\Anaconda33\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "[CV] .... dropout_rate=0.1, learn_rate=0.1, score=0.718, total=   8.4s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.1 ................................\n",
      "[CV] .... dropout_rate=0.1, learn_rate=0.1, score=0.771, total=   8.0s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.1 ................................\n",
      "[CV] .... dropout_rate=0.1, learn_rate=0.1, score=0.823, total=   7.4s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.01 ...............................\n",
      "[CV] ... dropout_rate=0.1, learn_rate=0.01, score=0.740, total=   8.3s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.01 ...............................\n",
      "[CV] ... dropout_rate=0.1, learn_rate=0.01, score=0.756, total=   7.9s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.01 ...............................\n",
      "[CV] ... dropout_rate=0.1, learn_rate=0.01, score=0.831, total=   8.2s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.001 ..............................\n",
      "[CV] .. dropout_rate=0.1, learn_rate=0.001, score=0.748, total=   9.3s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.001 ..............................\n",
      "[CV] .. dropout_rate=0.1, learn_rate=0.001, score=0.763, total=   9.2s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.001 ..............................\n",
      "[CV] .. dropout_rate=0.1, learn_rate=0.001, score=0.800, total=   9.8s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.1 ................................\n",
      "[CV] .... dropout_rate=0.2, learn_rate=0.1, score=0.718, total=   8.6s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.1 ................................\n",
      "[CV] .... dropout_rate=0.2, learn_rate=0.1, score=0.748, total=   9.3s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.1 ................................\n",
      "[CV] .... dropout_rate=0.2, learn_rate=0.1, score=0.785, total=   9.9s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.01 ...............................\n",
      "[CV] ... dropout_rate=0.2, learn_rate=0.01, score=0.748, total=  10.3s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.01 ...............................\n",
      "[CV] ... dropout_rate=0.2, learn_rate=0.01, score=0.748, total=   9.7s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.01 ...............................\n",
      "[CV] ... dropout_rate=0.2, learn_rate=0.01, score=0.823, total=  10.5s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.001 ..............................\n",
      "[CV] .. dropout_rate=0.2, learn_rate=0.001, score=0.748, total=   9.9s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.001 ..............................\n",
      "[CV] .. dropout_rate=0.2, learn_rate=0.001, score=0.771, total=  10.4s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.001 ..............................\n",
      "[CV] .. dropout_rate=0.2, learn_rate=0.001, score=0.808, total=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score 0.7959183647620435 , using {'dropout_rate': 0.0, 'learn_rate': 0.01} \n",
      "0.7780612202323213 , 0.02178523584090544 with : {'dropout_rate': 0.0, 'learn_rate': 0.1} \n",
      "0.7959183647620435 , 0.04664236281877595 with : {'dropout_rate': 0.0, 'learn_rate': 0.01} \n",
      "0.7270408046184754 , 0.020043924183272166 with : {'dropout_rate': 0.0, 'learn_rate': 0.001} \n",
      "0.7704081591598841 , 0.0430524149010169 with : {'dropout_rate': 0.1, 'learn_rate': 0.1} \n",
      "0.77551020392958 , 0.03942172171987488 with : {'dropout_rate': 0.1, 'learn_rate': 0.01} \n",
      "0.7704081571831995 , 0.021758740536289154 with : {'dropout_rate': 0.1, 'learn_rate': 0.001} \n",
      "0.7499999940699461 , 0.02739208015106309 with : {'dropout_rate': 0.2, 'learn_rate': 0.1} \n",
      "0.7729591880829967 , 0.03530307839688959 with : {'dropout_rate': 0.2, 'learn_rate': 0.01} \n",
      "0.7755102001282633 , 0.024525924203499666 with : {'dropout_rate': 0.2, 'learn_rate': 0.001} \n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "#WE need to optimize Learning Rate\n",
    "# function to define Model\n",
    "seed=6\n",
    "np.random.seed(seed)\n",
    "def  model_create_new(learn_rate,dropout_rate):\n",
    "    #Create Model\n",
    "    model=Sequential()\n",
    "    model.add(Dense(8,input_dim=8,kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # Prevents a Neuron to become too important , helps model to generalise\n",
    "    model.add(Dense(4,input_dim=8,kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    # dropout_rate is between 0 and 1\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    #Compile The Model\n",
    "    adam = Adam(lr = learn_rate)\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_new= KerasClassifier(build_fn= model_create_new,verbose=0,batch_size=40,epochs=25)\n",
    "# Best batch size and epochs found earlier\n",
    "\n",
    "\n",
    "# Define Grid Search\n",
    "\n",
    "learn_rate=[0.1,0.01,0.001]\n",
    "# Influences magnitude of change of parameters\n",
    "dropout_rate=[0.0,0.1,0.2]\n",
    "\n",
    "# make a dictionary for gridSearch\n",
    "param_grid=dict(learn_rate=learn_rate,dropout_rate=dropout_rate)\n",
    "\n",
    "#Build The Grid Search\n",
    "grid=GridSearchCV(estimator=model_new,param_grid=param_grid,cv=KFold(random_state=seed),verbose=5)\n",
    "\n",
    "grid_results=grid.fit(Xfin,y)\n",
    "\n",
    "# Summarise Results\n",
    "\n",
    "print(\"Best Score {} , using {} \".format(grid_results.best_score_,grid_results.best_params_))\n",
    "mean=grid_results.cv_results_['mean_test_score']\n",
    "stds=grid_results.cv_results_['std_test_score']\n",
    "params=grid_results.cv_results_['params']\n",
    "\n",
    "for mean,stdev,params in zip(mean,stds,params):\n",
    "    print(\"{} , {} with : {} \".format(mean,stdev,params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Initialization and Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dipto\\Anaconda33\\lib\\site-packages\\sklearn\\model_selection\\_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] activation=softmax, init=uniform ................................\n",
      "[CV] .... activation=softmax, init=uniform, score=0.695, total=  10.2s\n",
      "[CV] activation=softmax, init=uniform ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... activation=softmax, init=uniform, score=0.763, total=  10.1s\n",
      "[CV] activation=softmax, init=uniform ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   20.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... activation=softmax, init=uniform, score=0.800, total=  10.6s\n",
      "[CV] activation=softmax, init=normal .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   30.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... activation=softmax, init=normal, score=0.710, total=  10.9s\n",
      "[CV] activation=softmax, init=normal .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   41.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... activation=softmax, init=normal, score=0.771, total=  11.2s\n",
      "[CV] activation=softmax, init=normal .................................\n",
      "[CV] ..... activation=softmax, init=normal, score=0.808, total=  10.8s\n",
      "[CV] activation=softmax, init=zero ...................................\n",
      "[CV] ....... activation=softmax, init=zero, score=0.611, total=  11.4s\n",
      "[CV] activation=softmax, init=zero ...................................\n",
      "[CV] ....... activation=softmax, init=zero, score=0.695, total=  11.6s\n",
      "[CV] activation=softmax, init=zero ...................................\n",
      "[CV] ....... activation=softmax, init=zero, score=0.700, total=  10.9s\n",
      "[CV] activation=relu, init=uniform ...................................\n",
      "[CV] ....... activation=relu, init=uniform, score=0.733, total=  11.1s\n",
      "[CV] activation=relu, init=uniform ...................................\n",
      "[CV] ....... activation=relu, init=uniform, score=0.748, total=  10.6s\n",
      "[CV] activation=relu, init=uniform ...................................\n",
      "[CV] ....... activation=relu, init=uniform, score=0.838, total=  11.3s\n",
      "[CV] activation=relu, init=normal ....................................\n",
      "[CV] ........ activation=relu, init=normal, score=0.725, total=  11.3s\n",
      "[CV] activation=relu, init=normal ....................................\n",
      "[CV] ........ activation=relu, init=normal, score=0.771, total=  11.4s\n",
      "[CV] activation=relu, init=normal ....................................\n",
      "[CV] ........ activation=relu, init=normal, score=0.831, total=  11.9s\n",
      "[CV] activation=relu, init=zero ......................................\n",
      "[CV] .......... activation=relu, init=zero, score=0.611, total=  12.0s\n",
      "[CV] activation=relu, init=zero ......................................\n",
      "[CV] .......... activation=relu, init=zero, score=0.695, total=  13.6s\n",
      "[CV] activation=relu, init=zero ......................................\n",
      "[CV] .......... activation=relu, init=zero, score=0.700, total=  12.0s\n",
      "[CV] activation=tanh, init=uniform ...................................\n",
      "[CV] ....... activation=tanh, init=uniform, score=0.748, total=  11.9s\n",
      "[CV] activation=tanh, init=uniform ...................................\n",
      "[CV] ....... activation=tanh, init=uniform, score=0.771, total=  12.6s\n",
      "[CV] activation=tanh, init=uniform ...................................\n",
      "[CV] ....... activation=tanh, init=uniform, score=0.846, total=  12.6s\n",
      "[CV] activation=tanh, init=normal ....................................\n",
      "[CV] ........ activation=tanh, init=normal, score=0.740, total=  13.0s\n",
      "[CV] activation=tanh, init=normal ....................................\n",
      "[CV] ........ activation=tanh, init=normal, score=0.771, total=  13.6s\n",
      "[CV] activation=tanh, init=normal ....................................\n",
      "[CV] ........ activation=tanh, init=normal, score=0.838, total=  12.7s\n",
      "[CV] activation=tanh, init=zero ......................................\n",
      "[CV] .......... activation=tanh, init=zero, score=0.611, total=  13.2s\n",
      "[CV] activation=tanh, init=zero ......................................\n",
      "[CV] .......... activation=tanh, init=zero, score=0.695, total=  14.7s\n",
      "[CV] activation=tanh, init=zero ......................................\n",
      "[CV] .......... activation=tanh, init=zero, score=0.700, total=  13.9s\n",
      "[CV] activation=linear, init=uniform .................................\n",
      "[CV] ..... activation=linear, init=uniform, score=0.771, total=  13.8s\n",
      "[CV] activation=linear, init=uniform .................................\n",
      "[CV] ..... activation=linear, init=uniform, score=0.763, total=  14.3s\n",
      "[CV] activation=linear, init=uniform .................................\n",
      "[CV] ..... activation=linear, init=uniform, score=0.831, total=  14.7s\n",
      "[CV] activation=linear, init=normal ..................................\n",
      "[CV] ...... activation=linear, init=normal, score=0.771, total=  14.3s\n",
      "[CV] activation=linear, init=normal ..................................\n",
      "[CV] ...... activation=linear, init=normal, score=0.763, total=  15.2s\n",
      "[CV] activation=linear, init=normal ..................................\n",
      "[CV] ...... activation=linear, init=normal, score=0.838, total=  15.3s\n",
      "[CV] activation=linear, init=zero ....................................\n",
      "[CV] ........ activation=linear, init=zero, score=0.611, total=  14.9s\n",
      "[CV] activation=linear, init=zero ....................................\n",
      "[CV] ........ activation=linear, init=zero, score=0.695, total=  15.2s\n",
      "[CV] activation=linear, init=zero ....................................\n",
      "[CV] ........ activation=linear, init=zero, score=0.700, total=  16.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score 0.7908163260744543 , using {'activation': 'linear', 'init': 'normal'} \n",
      "0.7525510166068466 , 0.04365529000660255 with : {'activation': 'softmax', 'init': 'uniform'} \n",
      "0.7627551006723423 , 0.040312763309779176 with : {'activation': 'softmax', 'init': 'normal'} \n",
      "0.6683673428333535 , 0.04092231505753368 with : {'activation': 'softmax', 'init': 'zero'} \n",
      "0.7729591847378381 , 0.04656018682914353 with : {'activation': 'relu', 'init': 'uniform'} \n",
      "0.7755102054501066 , 0.04319314111244652 with : {'activation': 'relu', 'init': 'normal'} \n",
      "0.6683673428333535 , 0.04092231505753368 with : {'activation': 'relu', 'init': 'zero'} \n",
      "0.7882653141812402 , 0.041837549762974366 with : {'activation': 'tanh', 'init': 'uniform'} \n",
      "0.7831632645458592 , 0.04090311953983408 with : {'activation': 'tanh', 'init': 'normal'} \n",
      "0.6683673428333535 , 0.04092231505753368 with : {'activation': 'tanh', 'init': 'zero'} \n",
      "0.7882653080991336 , 0.03010204819047102 with : {'activation': 'linear', 'init': 'uniform'} \n",
      "0.7908163260744543 , 0.03370616232395781 with : {'activation': 'linear', 'init': 'normal'} \n",
      "0.6683673428333535 , 0.04092231505753368 with : {'activation': 'linear', 'init': 'zero'} \n"
     ]
    }
   ],
   "source": [
    "# function to define Model\n",
    "seed=6\n",
    "np.random.seed(seed)\n",
    "def  model_create_new(activation,init):\n",
    "    #Create Model\n",
    "    model=Sequential()\n",
    "    model.add(Dense(8,input_dim=8,kernel_initializer=init,activation=activation))\n",
    "    model.add(Dense(4,input_dim=8,kernel_initializer=init,activation=activation))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    #Compile The Model\n",
    "    adam = Adam(lr =0.01)\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_new= KerasClassifier(build_fn= model_create_new,verbose=0,batch_size=40,epochs=25)\n",
    "# Define Grid Search\n",
    "\n",
    "# Optimize the activation function and initializer\n",
    "activation=[\"softmax\",\"relu\",\"tanh\",\"linear\"]\n",
    "init=[\"uniform\",\"normal\",\"zero\"]\n",
    "\n",
    "# make a dictionary for gridSearch\n",
    "param_grid=dict(activation=activation,init =init)\n",
    "\n",
    "#Build The Grid Search\n",
    "grid=GridSearchCV(estimator=model_new,param_grid=param_grid,cv=KFold(random_state=seed),verbose=5)\n",
    "\n",
    "grid_results=grid.fit(Xfin,y)\n",
    "\n",
    "# Summarise Results\n",
    "\n",
    "print(\"Best Score {} , using {} \".format(grid_results.best_score_,grid_results.best_params_))\n",
    "mean=grid_results.cv_results_['mean_test_score']\n",
    "stds=grid_results.cv_results_['std_test_score']\n",
    "params=grid_results.cv_results_['params']\n",
    "\n",
    "for mean,stdev,params in zip(mean,stds,params):\n",
    "    print(\"{} , {} with : {} \".format(mean,stdev,params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No of Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.763, total=  15.6s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.763, total=  16.1s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   31.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.823, total=  15.3s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   46.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.763, total=  14.7s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.763, total=  14.7s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=4, score=0.838, total=  16.8s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.771, total=  17.8s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.771, total=  15.9s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.815, total=  17.4s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.763, total=  18.1s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.763, total=  18.0s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.823, total=  17.5s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.771, total=  16.9s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.763, total=  15.9s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.838, total=  16.5s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.771, total=  17.1s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.763, total=  17.1s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.831, total=  16.4s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.771, total=  18.0s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.763, total=  19.0s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.846, total=  19.4s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.763, total=  21.3s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.763, total=  19.1s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.823, total=  19.0s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.771, total=  20.3s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.763, total=  20.4s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.838, total=  21.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score 0.7933673440497748 , using {'neuron1': 16, 'neuron2': 2} \n",
      "0.7831632660663858 , 0.028115285089042093 with : {'neuron1': 4, 'neuron2': 2} \n",
      "0.7882653080991336 , 0.035358360413807126 with : {'neuron1': 4, 'neuron2': 4} \n",
      "0.7857142886032864 , 0.0208998572485492 with : {'neuron1': 4, 'neuron2': 8} \n",
      "0.7831632645458592 , 0.02811529584910769 with : {'neuron1': 8, 'neuron2': 2} \n",
      "0.7908163260744543 , 0.03370616232395781 with : {'neuron1': 8, 'neuron2': 4} \n",
      "0.7882653080991336 , 0.03010204819047102 with : {'neuron1': 8, 'neuron2': 8} \n",
      "0.7933673440497748 , 0.03731364977453912 with : {'neuron1': 16, 'neuron2': 2} \n",
      "0.7831632599842792 , 0.028115289373295223 with : {'neuron1': 16, 'neuron2': 4} \n",
      "0.7908163260744543 , 0.03370616232395781 with : {'neuron1': 16, 'neuron2': 8} \n"
     ]
    }
   ],
   "source": [
    "# function to define Model\n",
    "seed=6\n",
    "np.random.seed(seed)\n",
    "def  model_create_new(neuron1,neuron2):\n",
    "    #Create Model\n",
    "    model=Sequential()\n",
    "    model.add(Dense(neuron1,input_dim=8,kernel_initializer='normal',activation='linear'))\n",
    "    model.add(Dense(neuron2,input_dim=neuron1,kernel_initializer='normal',activation='linear'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    #Compile The Model\n",
    "    adam = Adam(lr =0.01)\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_new= KerasClassifier(build_fn= model_create_new,verbose=0,batch_size=40,epochs=25)\n",
    "# Define Grid Search\n",
    "\n",
    "# Optimize the neurons \n",
    "neuron1=[4,8,16]\n",
    "neuron2=[2,4,8]\n",
    "\n",
    "# make a dictionary for gridSearch\n",
    "param_grid=dict(neuron1=neuron1,neuron2=neuron2)\n",
    "\n",
    "#Build The Grid Search\n",
    "grid=GridSearchCV(estimator=model_new,param_grid=param_grid,cv=KFold(random_state=seed),verbose=5)\n",
    "\n",
    "grid_results=grid.fit(Xfin,y)\n",
    "\n",
    "# Summarise Results\n",
    "\n",
    "print(\"Best Score {} , using {} \".format(grid_results.best_score_,grid_results.best_params_))\n",
    "mean=grid_results.cv_results_['mean_test_score']\n",
    "stds=grid_results.cv_results_['std_test_score']\n",
    "params=grid_results.cv_results_['params']\n",
    "\n",
    "for mean,stdev,params in zip(mean,stds,params):\n",
    "    print(\"{} , {} with : {} \".format(mean,stdev,params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Optimal Predictions\n",
    "y_pred=grid.predict(Xfin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       262\n",
      "           1       0.73      0.57      0.64       130\n",
      "\n",
      "    accuracy                           0.79       392\n",
      "   macro avg       0.77      0.73      0.74       392\n",
      "weighted avg       0.78      0.79      0.78       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Accuracy\n",
    "print(accuracy_score(y,y_pred))\n",
    "\n",
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to define Model\n",
    "seed=6\n",
    "np.random.seed(seed)\n",
    "def  model_create_new():\n",
    "    #Create Model\n",
    "    model=Sequential()\n",
    "    model.add(Dense(16,input_dim=8,kernel_initializer='normal',activation='linear'))\n",
    "    model.add(Dense(2,input_dim=16,kernel_initializer='normal',activation='linear'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    #Compile The Model\n",
    "    adam = Adam(lr =0.01)\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=adam,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "final_model=model_create_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xfin, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (392, 8)\n",
      "Shape of y (392,)\n",
      "Shape of X train: (262, 8)\n",
      "Shape of y train (262,)\n",
      "Shape of X test: (130, 8)\n",
      "Shape of y test (130,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X:\",Xfin.shape)\n",
    "print(\"Shape of y\",y.shape)\n",
    "print(\"Shape of X train:\",X_train.shape)\n",
    "print(\"Shape of y train\",y_train.shape)\n",
    "print(\"Shape of X test:\",X_test.shape)\n",
    "print(\"Shape of y test\",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "262/262 [==============================] - 14s 52ms/step - loss: 0.6217 - acc: 0.7595\n",
      "Epoch 2/25\n",
      "262/262 [==============================] - 0s 239us/step - loss: 0.4743 - acc: 0.8130\n",
      "Epoch 3/25\n",
      "262/262 [==============================] - 0s 200us/step - loss: 0.4356 - acc: 0.7863\n",
      "Epoch 4/25\n",
      "262/262 [==============================] - 0s 199us/step - loss: 0.4307 - acc: 0.7748\n",
      "Epoch 5/25\n",
      "262/262 [==============================] - 0s 207us/step - loss: 0.4200 - acc: 0.7939\n",
      "Epoch 6/25\n",
      "262/262 [==============================] - 0s 212us/step - loss: 0.4160 - acc: 0.7863\n",
      "Epoch 7/25\n",
      "262/262 [==============================] - 0s 220us/step - loss: 0.4146 - acc: 0.7939\n",
      "Epoch 8/25\n",
      "262/262 [==============================] - 0s 199us/step - loss: 0.4149 - acc: 0.8015\n",
      "Epoch 9/25\n",
      "262/262 [==============================] - 0s 180us/step - loss: 0.4132 - acc: 0.8015\n",
      "Epoch 10/25\n",
      "262/262 [==============================] - 0s 208us/step - loss: 0.4151 - acc: 0.8015\n",
      "Epoch 11/25\n",
      "262/262 [==============================] - 0s 186us/step - loss: 0.4132 - acc: 0.8015\n",
      "Epoch 12/25\n",
      "262/262 [==============================] - 0s 188us/step - loss: 0.4152 - acc: 0.8053\n",
      "Epoch 13/25\n",
      "262/262 [==============================] - 0s 243us/step - loss: 0.4143 - acc: 0.8015\n",
      "Epoch 14/25\n",
      "262/262 [==============================] - 0s 234us/step - loss: 0.4132 - acc: 0.7977\n",
      "Epoch 15/25\n",
      "262/262 [==============================] - 0s 239us/step - loss: 0.4158 - acc: 0.7977\n",
      "Epoch 16/25\n",
      "262/262 [==============================] - 0s 200us/step - loss: 0.4131 - acc: 0.7977\n",
      "Epoch 17/25\n",
      "262/262 [==============================] - 0s 212us/step - loss: 0.4158 - acc: 0.8053\n",
      "Epoch 18/25\n",
      "262/262 [==============================] - 0s 229us/step - loss: 0.4141 - acc: 0.8092\n",
      "Epoch 19/25\n",
      "262/262 [==============================] - 0s 204us/step - loss: 0.4140 - acc: 0.7977\n",
      "Epoch 20/25\n",
      "262/262 [==============================] - 0s 225us/step - loss: 0.4145 - acc: 0.7939\n",
      "Epoch 21/25\n",
      "262/262 [==============================] - 0s 370us/step - loss: 0.4150 - acc: 0.8015\n",
      "Epoch 22/25\n",
      "262/262 [==============================] - 0s 197us/step - loss: 0.4143 - acc: 0.8015\n",
      "Epoch 23/25\n",
      "262/262 [==============================] - 0s 201us/step - loss: 0.4154 - acc: 0.8015\n",
      "Epoch 24/25\n",
      "262/262 [==============================] - 0s 192us/step - loss: 0.4158 - acc: 0.7939\n",
      "Epoch 25/25\n",
      "262/262 [==============================] - 0s 218us/step - loss: 0.4150 - acc: 0.7863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22e15b32438>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "final_model.fit(X_train,y_train,batch_size=40,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict from testing set\n",
    "preds= final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=(preds > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7384615384615385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82        89\n",
      "           1       0.60      0.51      0.55        41\n",
      "\n",
      "    accuracy                           0.74       130\n",
      "   macro avg       0.69      0.68      0.68       130\n",
      "weighted avg       0.73      0.74      0.73       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Accuracy\n",
    "print(accuracy_score(y_test,preds))\n",
    "\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
